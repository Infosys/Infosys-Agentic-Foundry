{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Agentic Foundry","text":"<p>Agentic Foundry is an open-source framework designed to empower developers to create, configure, and deploy customizable AI agents. By using predefined templates, this platform ensures seamless tool integration and streamlines agentic workflow development.</p>"},{"location":"#what-is-agentic-foundry","title":"What is Agentic Foundry","text":"<p>The Agentic Foundry enables the efficient creation and deployment of AI agents by offering customizable templates and a set of powerful tools. These agents can be tailored to specific roles and personas, and developers can integrate their own custom tools to suit various needs.</p> <p>Key Components:</p> <ul> <li> <p><code>Agent Configuration:</code> A reusable agent-building template that helps in creating agents with specific roles or persona definitions.</p> </li> <li> <p><code>Tool Configuration:</code> Manage all the supported tools available for developers. Provides a framework for integrating and onboarding custom tools.</p> </li> </ul>"},{"location":"#why-to-use-agentic-foundry","title":"Why to Use Agentic Foundry","text":"<p>The Agentic Foundry  offers a comprehensive solution with continually evolving new features:</p> <ol> <li> <p>Agent-as-a-Service:      Open-source framework-based solution that allows users to quickly configure agents and tools. End-users can interact with agents via a conversational interface.</p> </li> <li> <p>Vertical Agents:    A suite of agents tailored for various industry personas. These agents represent specific workflows for different domains, including:</p> <ul> <li> <p><code>Finance:</code></p> <ul> <li>Financial statement analysis</li> <li>Risk assessment and management</li> <li>Fraud prevention</li> </ul> </li> <li> <p><code>Healthcare:</code></p> <ul> <li>Medical record analysis</li> <li>Diagnostic assistance</li> <li>Treatment plan recommendation</li> </ul> </li> <li> <p><code>Insurance:</code></p> <ul> <li>Policy underwriting assistance</li> <li>Claim fraud detection</li> <li>Risk assessment for policy pricing</li> </ul> </li> <li> <p><code>Retail:</code></p> <ul> <li>Customer segmentation</li> <li>Personalized product recommendations</li> <li>Price optimization</li> </ul> </li> <li> <p><code>Communication:</code></p> <ul> <li>Customer churn prediction</li> <li>Fraud detection in calls and data usage</li> <li>Customer service automation</li> </ul> </li> <li> <p><code>Manufacturing:</code></p> <ul> <li>Quality control inspection</li> <li>Predictive maintenance</li> <li>Product lifecycle management</li> </ul> </li> </ul> </li> <li> <p>Horizontal Agents</p> <ul> <li>These agents offer common functionality across industries, such as:<ul> <li>Email sending</li> <li>File search</li> <li>Agentic RAG (Retrieval-Augmented Generation). </li> <li>SDLC</li> </ul> </li> </ul> </li> </ol>"},{"location":"#how-to-use-agentic-foundry","title":"How to Use Agentic Foundry","text":"<p>Follow this simple flow to start using the Agentic Foundry:</p> <ul> <li> <p><code>Upload the Required Files:</code> Begin by uploading all necessary files required for the agent to function. If the agent depends on a database, ensure you upload the relevant database files in the File section. Supported database formats include SQLite files (.db, .sqlite) and PostgreSQL dump files (.sql). Additionally, upload any PDFs or other supporting documents that the agent may need to process or reference.</p> </li> <li> <p><code>Create and Onboard Tools:</code> Develop the required tools and onboard them into the system.</p> </li> <li> <p><code>Create the Agent:</code>  Build your AI agent by adding the necessary tools and configuring it according to the desired role.</p> </li> <li> <p><code>Start Using the Agent:</code> Once your agent is configured, head to the Inference section and select the agent to start using it for real-time tasks.</p> </li> </ul> <p>     With Agentic Foundry, developers have the power to create highly customizable AI agents for various applications \u2014 empowering businesses and individuals to automate workflows and achieve efficiency with ease. </p>"},{"location":"Architecture/","title":"Architecture","text":""},{"location":"Architecture/#agents","title":"Agents","text":"<ul> <li>Reusable Templates: Developers can utilize predefined, reusable templates to streamline the creation of agents. These templates allow for the rapid definition of agents with specific roles or persona attributes, ensuring consistency and reducing development time.</li> <li>Customizable Roles: Agents can be tailored to meet the unique requirements of an application by defining their behaviors, objectives, and interaction styles. This flexibility enables developers to create agents that align with specific use cases or business goals.</li> </ul> <p>We mainly have three types of templates: React, Multi, and Meta.</p> <p>React Template: </p> <p>The ReAct(Reasoning and Acting) agent combines reasoning traces with action execution. It uses a step by step thought process to determine what tool to use, executes it, observe the result, and continues until it can return a final answer.</p> <p><code>Use Case</code> : </p> <p>When the task requires step-by-step reasoning and immediate action execution.</p> <p><code>Examples</code> :</p> <ol> <li>Answering user queries by reasoning through available data and tools.</li> <li>Performing calculations or data lookups with a clear sequence of steps.</li> <li>Interactive troubleshooting or debugging tasks where the agent needs to reason and act iteratively.</li> </ol> <p>Multi Template: </p> <p>The Multi Agent operates on the Planner-Executor-Critic paradigm. It begins with a Planner Agent that generates a step-by-step plan based on the user query. The Executor Agent then executes each step of the plan. The Critic evaluates the outputs by scoring the results of each step.</p> <p><code>Use Case</code> : </p> <p>When the task involves a complex workflow that requires planning, execution, and evaluation.</p> <p><code>Examples</code> :</p> <ol> <li>Multi-step project management tasks where a detailed plan is needed.</li> <li>Executing a sequence of dependent tasks, such as data processing pipelines.</li> <li>Scenarios where outputs need to be evaluated and scored for quality or correctness.</li> </ol> <p>Meta Template: </p> <p>Meta templates are used for agents that require higher-level reasoning or orchestration capabilities. These agents can manage other agents, coordinate tasks, or oversee complex processes, making them suitable for supervisory or managerial roles within the system.</p> <p><code>Use Case</code> : </p> <p>When the task requires higher-level orchestration, coordination of multiple agents, or managing complex processes.</p> <p><code>Examples</code> :</p> <ol> <li>Supervising multiple agents working on different parts of a large project.</li> <li>Overseeing workflows that involve dynamic task allocation and coordination.</li> <li>Managing and optimizing resource allocation across multiple agents or tools.</li> </ol>"},{"location":"Architecture/#tools","title":"Tools","text":"<ul> <li>Tool Management: A centralized interface is provided to manage all supported tools. This interface simplifies the process of enabling, disabling, or configuring tools, ensuring that developers have full control over the orchestration environment.</li> <li>Custom Tool Integration: The framework supports seamless integration of custom tools, allowing developers to onboard new tools without disrupting existing workflows. This ensures scalability and adaptability as new tools or technologies emerge.</li> </ul>"},{"location":"Architecture/#memory","title":"Memory","text":"<ul> <li>Session Memory: Designed to retain context-specific data during the current session, session memory ensures that interactions remain coherent and contextually relevant. This is particularly useful for multi-turn conversations or complex workflows.</li> <li>Persistent Memory: Persistent memory goes beyond the session, storing user behaviors, preferences, and historical data over time. This enables the system to provide personalized experiences, maintain long-term context, and adapt to user needs dynamically.</li> </ul>"},{"location":"Architecture/#architecture-design-diagram","title":"Architecture Design Diagram","text":"<p>The diagram titled \"Orchestration Design\" illustrates the architecture of the orchestration system. It highlights the interaction between agents, tools, and memory components. Key elements include:</p> <ol> <li>Agents: Represented as modular entities that interact with tools and memory to perform tasks or provide responses.</li> <li>Tools: Shown as a collection of integrated utilities that agents can leverage to enhance their functionality.</li> <li>Memory: Depicted as a dual-layered system comprising session memory for short-term context and persistent memory for long-term personalization.</li> <li>Workflow: The diagram emphasizes the seamless flow of data and interactions between these components, ensuring a cohesive and efficient orchestration process.</li> </ol> <p>This visual representation underscores the modularity and scalability of the system, making it easier for developers to understand and extend the orchestration framework.</p>"},{"location":"Architecture/#agent-as-a-service-reference-architecture","title":"Agent-as-a-Service: Reference Architecture","text":""},{"location":"Features/","title":"Features","text":"<p>Agentic Foundary  provides comprehensive capabilities for building and managing intelligent agents with minimal coding effort.</p>"},{"location":"Features/#features-overview","title":"Features Overview","text":"Low-Code Agent Creation Easy Agent &amp; Tool Management In-Platform Customization Reusable Components Human-in-the-Loop Dynamic Workflow Automation Transparent Execution Agentic Foundary Features Feedback-Driven Learning Orchestrator Agent Custom Knowledge Bases LLM-Based Evaluation Telemetry &amp; Monitoring Clear Documentation Flexible Model Support"},{"location":"Features/#feature-descriptions","title":"Feature Descriptions","text":""},{"location":"Features/#core-development-features","title":"Core Development Features","text":"<ul> <li> <p>Low-Code Agent Creation \u2013 Just provide tool code and workflow; we handle the rest.</p> </li> <li> <p>Easy Agent &amp; Tool Management \u2013 Seamlessly onboard, update, or remove components.</p> </li> <li> <p>In-Platform Customization \u2013 Tweak tools, workflows, and logic directly within the framework.</p> </li> <li> <p>Reusable Components \u2013 Modular agents and tools for efficient reuse.</p> </li> </ul>"},{"location":"Features/#workflow-control-features","title":"Workflow &amp; Control Features","text":"<ul> <li> <p>Human-in-the-Loop \u2013 Add manual control for critical steps when needed.</p> </li> <li> <p>Dynamic Workflow Automation \u2013 Adapts in real-time to evolving business needs.</p> </li> <li> <p>Transparent Execution \u2013 See every step your agent takes to reach its response.</p> </li> <li> <p>Orchestrator Agent \u2013 Coordinate multiple agents through a central controller.</p> </li> </ul>"},{"location":"Features/#intelligence-learning-features","title":"Intelligence &amp; Learning Features","text":"<ul> <li> <p>Feedback-Driven Learning \u2013 Agents learn and improve from user input.</p> </li> <li> <p>Custom Knowledge Bases \u2013 Equip agents with domain-specific intelligence.</p> </li> <li> <p>LLM-Based Evaluation \u2013 Assess agent quality with LLM-as-a-judge scoring.</p> </li> <li> <p>Flexible Model Support \u2013 Plug in different LLMs or SLMs as per task needs.</p> </li> </ul>"},{"location":"Features/#operations-support-features","title":"Operations &amp; Support Features","text":"<ul> <li> <p>Telemetry &amp; Monitoring \u2013 Logs and metrics via OpenTelemetry, Arize Phoenix and Grafana.</p> </li> <li> <p>Clear Documentation \u2013 Well-organized developer docs built with MkDocs.</p> </li> </ul>"},{"location":"Tool%20Interrupt/","title":"Tool Interrupt","text":"<p>The Tool Interrupt feature provides users with enhanced control over how tools are executed within the framework. This feature allows users to review, modify, and approve tool executions before they are processed, giving greater transparency and control over the agent's behavior.</p>"},{"location":"Tool%20Interrupt/#overview","title":"Overview","text":"<p>Tool Interrupt is a toggle feature available in the inference section of the framework that changes how tools are called and executed when processing user queries.</p> <p>Toggle Location :</p> <p>The Tool Interrupt toggle button can be found in the Inference section of the framework interface.</p>"},{"location":"Tool%20Interrupt/#operating-modes","title":"Operating Modes","text":""},{"location":"Tool%20Interrupt/#without-tool-interrupt-default-mode","title":"Without Tool Interrupt (Default Mode)","text":"<p>When Tool Interrupt is disabled, the system operates in automatic mode:</p> <ul> <li>User submits a query</li> <li>The agent automatically identifies required tools</li> <li>Tools are called sequentially with parameters derived from the user query</li> <li>Final answer is provided directly without user intervention</li> </ul> <p>Example: - User Query: <code>2-10*5</code> - System Response: <code>The answer is -48</code></p>"},{"location":"Tool%20Interrupt/#with-tool-interrupt-interactive-mode","title":"With Tool Interrupt (Interactive Mode)","text":"<p>When Tool Interrupt is enabled, the system operates in interactive mode :</p> <ul> <li>User submits a query</li> <li>System displays the first tool to be called with its parameters</li> <li>User can review and modify parameters before execution</li> <li>User approves each tool execution step-by-step</li> <li>System shows dependent tools in sequence</li> <li>Final answer is provided after all approvals</li> </ul>"},{"location":"Tool%20Interrupt/#tool-interrupt-workflow","title":"Tool Interrupt Workflow","text":"<p>Step 1: Tool Identification</p> <p>When a user submits a query, the system identifies the first tool that needs to be called and displays:</p> <ul> <li>Tool Name: The specific tool to be executed</li> <li>Parameters: The arguments that will be passed to the tool</li> </ul> <p>Step 2: Parameter Review and Editing Users have two options:</p> <p>Option A: Edit Parameters</p> <ul> <li>Click the \"Edit\" button</li> <li>Modify the tool arguments as needed</li> <li>Confirm changes</li> </ul> <p>Option B: Approve Parameters</p> <ul> <li>Click the \"\ud83d\udc4d\" (thumbs up) button to approve current parameters</li> <li>System proceeds with the tool execution</li> </ul> <p>Step 3: Sequential Tool Execution</p> <ul> <li>After approval, the tool executes with the specified parameters</li> <li>If additional tools are required, the system displays the next tool in the sequence</li> <li>Process repeats until all dependent tools are executed</li> </ul> <p>Step 4: Final Result</p> <ul> <li>Once all tools have been executed, the system provides the final answer</li> </ul> <p>Practical Example: Calculator Agent</p> <p>Let's walk through a detailed example using a Calculator Agent with the following tools:</p> <ul> <li><code>add(a, b)</code> - Addition</li> <li><code>sub(a, b)</code> - Subtraction  </li> <li><code>mult(a, b)</code> - Multiplication</li> <li><code>div(a, b)</code> - Division</li> </ul> <p>User Query: <code>2-10*5</code></p> <p>Without Tool Interrupt:</p> <pre><code>Input: 2-10*5\nOutput: The answer is -48\n</code></pre> <p>With Tool Interrupt:</p> <p>Step 1: System identifies first operation</p> <pre><code>Tool to call: mult(a, b)\nParameters: a=10, b=5\n</code></pre> <p>User Options:</p> <ul> <li>Edit: Modify parameters (e.g., change to a=5, b=2)</li> </ul> <p>Click on the Edit option as shown below to modify the parameters:</p> <p></p> <p>The image below shows where you can edit the parameters:</p> <p></p> <ul> <li>\ud83d\udc4d: Approve current parameters.</li> </ul> <p></p> <p>Step 2: If user approves original parameters</p> <pre><code>Tool executed: mult(10, 5) = 50\nNext tool: sub(a, b)\nParameters: a=2, b=50\n</code></pre> <p>Step 3: User approves subtraction</p> <pre><code>Tool executed: sub(2, 50) = -48\nFinal Answer: -48\n</code></pre> <p>Alternative Step 2: If user edits multiplication parameters</p> <pre><code>Modified parameters: mult(5, 2) = 10\nNext tool: sub(a, b)\nParameters: a=2, b=10\n</code></pre> <p>Final Result with edited parameters:</p> <pre><code>Tool executed: sub(2, 10) = -8\nFinal Answer: -8\n</code></pre>"},{"location":"Tool%20Interrupt/#benefits-of-tool-interrupt","title":"Benefits of Tool Interrupt","text":"<p>Enhanced Control</p> <ul> <li>Users can intervene in the tool execution process</li> <li>Ability to correct parameters before execution</li> <li>Prevention of unintended tool calls</li> </ul> <p>Transparency</p> <ul> <li>Clear visibility into which tools are being called</li> <li>Understanding of parameter values being used</li> <li>Step-by-step execution visibility</li> </ul> <p>Debugging and Testing - Ability to test different parameter combinations - Easy identification of tool execution issues - Validation of tool selection logic</p> <p>Educational Value - Understanding of how complex queries are broken down - Learning about tool dependencies and execution order - Insight into agent decision-making process</p>"},{"location":"Tool%20Interrupt/#best-practices","title":"Best Practices","text":"<p>Enable Tool Interrupt when: - Testing new agent configurations - Working with sensitive data or operations - Learning how tools interact with each other - Debugging complex queries - Need precise control over tool parameters</p> <p>Disable Tool Interrupt when: - Running routine, well-tested operations - Processing bulk queries - Working with trusted tool configurations - Need fast, automated responses</p> <p>Parameter Editing Guidelines :</p> <ul> <li>Review Carefully: Always review the suggested parameters before editing</li> <li>Understand Dependencies: Consider how parameter changes might affect subsequent tools</li> <li>Test Incrementally: Make small changes and observe results</li> <li>Document Changes: Keep track of parameter modifications for future reference</li> </ul>"},{"location":"Tool_Validation/","title":"Tool Validation Rules","text":""},{"location":"Tool_Validation/#overview","title":"Overview","text":"<p>This document outlines the validation process for onboarding new tools. Before any tool is added, it must pass through a validation checklist to ensure quality, security, and reliability.</p>"},{"location":"Tool_Validation/#validation-process","title":"Validation Process","text":"<ol> <li>Code Analysis: Tool code is analyzed against validation criteria</li> <li>Result Classification: Each item is marked as Pass, Warning, or Error</li> <li>User Decision: If issues are found, user decides whether to proceed</li> <li>Tool Addition: Tool is added or rejected based on user consent</li> </ol>"},{"location":"Tool_Validation/#validation-checklist","title":"Validation Checklist","text":"<p>All tools must pass these validation rules before onboarding: 1. Testing :</p> <ul> <li>This is an Error level validation</li> <li>Must include test cases to validate the tool</li> </ul> <p>2. Tool Name :</p> <ul> <li>This is a Warning level validation</li> <li>Tool names must be descriptive and unambiguous</li> <li>Avoid overloaded names</li> </ul> <p>3. Arguments :</p> <ul> <li>This is an Error level validation</li> <li>All inputs must be explicitly named and typed</li> <li>Use JSON-serializable types (str, int, float, bool, list, dict)</li> </ul> <p>4. Fail-Safes :</p> <ul> <li>This is a Warning level validation</li> <li>Include clear error messages and fallbacks for invalid inputs</li> <li>Enable meaningful error handling</li> </ul> <p>5. Side Effects :</p> <ul> <li>This is an Error level validation</li> <li>Avoid tools with dangerous or irreversible side effects unless absolutely necessary</li> <li>Tools that delete data or send irreversible commands require justification</li> </ul> <p>6. Credential Handling :</p> <ul> <li>This is a Warning level validation</li> <li>Use environment variables or secret managers</li> <li>Never hardcode API keys or credentials</li> </ul> <p>7. Import Statements:</p> <ul> <li>This is an Error level validation</li> <li>Tools must include explicit and proper import statements for all dependencies</li> </ul> <p>8. Output and Input Handling:</p> <ul> <li>This is an Error level validation</li> <li>Avoid using <code>print</code> statements within the tool</li> <li>Tools must not directly prompt for or accept user inputs in their code</li> </ul>"},{"location":"Tool_Validation/#rule-classifications","title":"Rule Classifications","text":"<ul> <li>Error: Critical issues that strongly indicate revision needed</li> <li>Warning: Issues that should be addressed but don't block deployment</li> <li>Pass: Requirements met</li> </ul>"},{"location":"Agents%20Design/Multi%20Agent%20Design/","title":"Multi Agent Design","text":""},{"location":"Agents%20Design/Multi%20Agent%20Design/#multi-agent-design","title":"Multi Agent Design","text":"Multi Agent Without Feedback Multi Agent With Feedback <p>The Multi Agent operates on the Planner-Executor-Critic paradigm, which involves three key components:</p> <ol> <li>Planner Agent: Generates a detailed step-by-step plan based on the user query.</li> <li>Executor Agent: Executes each step of the plan sequentially.</li> <li>Critic: Evaluates the outputs of each step by scoring the results.</li> </ol> <p>The framework supports two types of Multi Agents, differentiated by their feedback mechanism: With Feedback (Human-in-the-Loop) and Without Feedback (Fully Automated). Users have the flexibility to enable or disable the Human-in-the-Loop feature based on their requirements.</p> <p>How It Works:</p>"},{"location":"Agents%20Design/Multi%20Agent%20Design/#1-multi-agent-without-feedback","title":"1. Multi Agent Without Feedback","text":"<ol> <li>The user provides a query, and the <code>Planner Agent</code> generates a clear, step-by-step plan.</li> <li>The plan is passed to the <code>Executor Agent</code>, which executes each step sequentially.</li> <li>The <code>Response Generator Agent</code> processes the results and sends them to the <code>Critic</code> for evaluation.</li> <li>The <code>Critic</code> scores the response:</li> <li>If the score meets the threshold, the final response is returned to the user.</li> <li>If the score is below the threshold, the response is sent back to the <code>Critic-Based Planner Agent</code> for refinement. The process repeats until an accurate response is generated.</li> </ol> <p>This entire process happens internally and is not visible to the user. The user only sees the final response, ensuring a seamless experience.</p>"},{"location":"Agents%20Design/Multi%20Agent%20Design/#2-multi-agent-with-feedback","title":"2. Multi Agent With Feedback","text":"<ol> <li>After the <code>Planner Agent</code> generates a step-by-step plan, the user can review the plan.</li> <li>If the <code>Human-in-the-Loop</code> option is enabled:</li> <li><code>Approval</code>: If the user is satisfied with the plan, they can approve it by clicking a thumbs-up or like button. The approved plan is then passed to the <code>Executor Agent</code>, which executes each step sequentially. The results are evaluated by the <code>Critic</code>, and the process continues as in the <code>Without Feedback</code> mode.</li> <li><code>Rejection</code>: If the user is not satisfied with the plan, they can reject it by clicking a thumbs-down button and providing feedback. This feedback is sent to the <code>Re-Planner Agent</code>, which refines the plan based on the user's input. The process repeats until the user approves the plan.</li> <li>Once the plan is finalized and approved, the system proceeds with execution and evaluation, ultimately delivering the final response to the user.</li> </ol> <p>This mode allows users to actively participate in the planning process, ensuring the generated plan aligns with their expectations. By incorporating user feedback at critical stages, the <code>With Feedback</code> mode enhances accuracy, adaptability, and user satisfaction.</p>"},{"location":"Agents%20Design/Orchestration%20Meta%20Agent%20Design/","title":"Orchestration Meta Agent Design","text":""},{"location":"Agents%20Design/Orchestration%20Meta%20Agent%20Design/#meta-agent-design","title":"Meta Agent Design","text":"<p>The <code>Meta Agent</code>, also known as the <code>Supervisor Agent</code>, orchestrates a combination of worker agents \u2014 which can be ReAct agents, Multi-Agents, or hybrids of both. It manages and supervises these worker agents by deciding which agent(s) to invoke based on the user's query and coordinates their responses to deliver the final answer.</p> <p>How It Works:</p> <ol> <li> <p>User Query Input:</p> <p>The user query is received by the Meta Agent, which acts as the central supervisor.</p> </li> <li> <p>Worker Agent Selection:</p> <p>The Meta Agent analyzes the query and decides which type of worker agent (ReAct, Multi-Agent, or a combination) is best suited to handle the task based on the query\u2019s complexity, required capabilities, and context.</p> </li> <li> <p>Delegation to Worker Agent(s):</p> <p>The selected worker agent(s) are called upon to process the query. Each worker agent internally uses their bound tools \u2014 small Python functions implementing specific logic or actions \u2014 to perform their tasks.</p> </li> <li> <p>Worker Agent Processing:</p> <ul> <li> <p>ReAct Agents proceed through their iterative reasoning and acting cycle (reasoning about tools, acting, observing results, and refining).</p> </li> <li> <p>Multi-Agents may work collaboratively or independently, coordinating their tools and knowledge to resolve the query.</p> </li> </ul> </li> <li> <p>Response Aggregation:</p> <p>The Meta Agent collects and evaluates responses from the worker agent(s).</p> </li> <li> <p>Decision Making &amp; Final Answer:</p> <p>Based on aggregated responses and overall context, the Meta Agent decides:</p> <ul> <li> <p>To invoke additional worker agents if needed, or</p> </li> <li> <p>To conclude and return the final consolidated answer to the user.</p> </li> </ul> </li> </ol> <p>The Meta Agent (Supervisor) acts as a high-level controller that dynamically delegates tasks to the most appropriate internal worker agent(s), whether ReAct, Multi-Agent, or a hybrid. It handles query routing, response coordination, and final decision-making, ensuring a flexible and efficient multi-layered reasoning and action system that leverages specialized tools bound to each agent.</p>"},{"location":"Agents%20Design/React%20Agent%20Design/","title":"React Agent Design","text":""},{"location":"Agents%20Design/React%20Agent%20Design/#react-agent-design","title":"React Agent Design","text":"<p>The <code>ReAct (Reasoning and Acting)</code> agent is designed to combine reasoning traces with action execution. It follows a step-by-step process to determine the appropriate tools to use, execute actions, observe the results, and iteratively refine its decisions until it arrives at a final answer.</p> <p>How It Works:</p> <ol> <li> <p>User Query Input:    The process begins with the user query being passed to the React Agent.</p> </li> <li> <p>Reasoning Phase:    The agent analyzes the query and reasons about which tools are required to address the task. This reasoning is based on the context and the nature of the query.</p> </li> <li> <p>Action Phase:    The agent takes action by invoking the appropriate tool(s). For example, it may call an external API, perform a computation, or retrieve data.</p> </li> <li> <p>Feedback Loop:    The response from the tool is fed back into the React Agent. The agent evaluates the tool's output and determines whether additional tools need to be called or if the process can be concluded.</p> </li> <li> <p>Decision Making:    Based on the user query and the results obtained from the tools, the agent decides:</p> <ul> <li>Whether to call another tool for further processing.</li> <li>Whether to stop and return the final answer to the user.</li> </ul> </li> </ol> <p>This iterative reasoning and acting process ensures that the React Agent can handle complex queries efficiently by dynamically adapting its actions based on the context and intermediate results. It is particularly useful for scenarios requiring logical decision-making and multi-step workflows.</p>"},{"location":"Agents%20Design/overview/","title":"Overview","text":"<p>Agentic Foundry supports three types of agent templates: </p> <ul> <li> <p>React Agent: Designed for single-task operations, React Agents use a step-by-step reasoning process to determine and execute the appropriate actions. They are ideal for scenarios requiring precise and efficient task execution. Learn more in the React Agent Design document.</p> </li> <li> <p>Multi Agent: Multi Agents enable collaboration between specialized agents to achieve complex objectives. They follow the Planner-Executor-Critic paradigm, ensuring tasks are planned, executed, and evaluated effectively. Detailed information is available in the Multi Agent Design document.</p> </li> <li> <p>Meta Agent: Acting as orchestrators, Meta Agents manage and coordinate other agents to achieve high-level goals. They dynamically adapt to context and task requirements, ensuring seamless execution. Explore their design in the Meta Agent Design document.</p> </li> </ul> <p>Each agent template is highly customizable, allowing developers to tailor them to specific use cases, making Agentic Foundry a robust platform for building intelligent systems.</p>"},{"location":"Database%20setup/Database%20Setup/","title":"PostgreSQL Setup Guide","text":""},{"location":"Database%20setup/Database%20Setup/#installation-on-vm","title":"Installation on VM","text":"<ol> <li>Download the PostgreSQL installation wizard and start it up. </li> <li>Choose the default directory or customize as required. </li> <li> <p>All the components will be selected by default and will be useful,  so keep them as it is and Next to continue. </p> <p></p> </li> <li> <p>Choose the default Data directory or change as required. </p> </li> <li> <p>Create a password for postgres (superuser) - This password will be used in the connection string for connecting to the database: <code>postgresql://postgres:password@localhost:port/database</code>.</p> <p></p> </li> <li> <p>Set the port number (default: 5432) or change if required. </p> </li> <li> <p>Use the Locale field to specify the locale that will be used by the new database cluster. The Default locale is the operating system locale. You can leave this as is and click next to continue.</p> <p></p> </li> <li> <p>Click Next to continue.</p> <p></p> </li> <li> <p>Click Next to start the installation. </p> </li> <li>After installation is complete, there will be a checked check box which asks if additional tools should be installed to complement your postgres installation using Stack Builder.</li> <li> <p>You should uncheck this as it is not necessary, and it is also not possible as the url gets blocked by the VM.</p> <p></p> </li> </ol>"},{"location":"Database%20setup/Database%20Setup/#installation-on-local","title":"Installation on local","text":"<ol> <li>Install PostgreSQL from company portal</li> <li> <p>Verify installation:</p> <ul> <li>Open SQL Shell (psql)</li> <li>Default username, password, database: <code>postgres</code></li> <li> <p>Default port: <code>5432</code> </p> <p></p> </li> <li> <p>Default connection string: <code>postgresql://postgres:postgres@localhost:5432/postgres</code></p> </li> <li>Connection String Format</li> </ul> <p><code>postgresql://username:password@host:port/database</code></p> <p>Example:</p> <p><code>postgresql://postgres:postgres@localhost:5432/postgres</code></p> </li> <li> <p>Run <code>\\l</code> command to check list of databases, username, and password status</p> <p></p> </li> </ol>"},{"location":"Database%20setup/Database%20Setup/#database-setup","title":"Database Setup","text":"<p>Environment Configuration</p> <p>Create a <code>.env</code> file with the following variables:</p> <pre><code>DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres\n\n# PostgreSQL Configuration\nPOSTGRESQL_HOST=localhost\nPOSTGRESQL_USER=postgres\nPOSTGRESQL_PASSWORD=postgres\nDATABASE=your_database_name\nPOSTGRESQL_DATABASE_URL=postgresql://postgres:postgres@localhost:5432/your_database_name?sslmode=disable\n</code></pre> <p>Database Creation</p> <p>1. Define required databases in a list variable in <code>database_manager.py</code> file:</p> <pre><code>REQUIRED_DATABASES = [\n    \"feedback_learning\",\n    \"telemetry_logs\", \n    \"agentic_workflow_as_service_database\",\n    \"login\",\n    \"logs\",\n    \"arize_traces\"\n]\n</code></pre> <p>2. Load environment variables in <code>database_manager.py</code> file:</p> <pre><code>Postgre_string = os.getenv(\"DATABASE_URL\")\nPOSTGRESQL_HOST = os.getenv(\"POSTGRESQL_HOST\", \"\")\nPOSTGRESQL_USER = os.getenv(\"POSTGRESQL_USER\", \"\")\nPOSTGRESQL_PASSWORD = os.getenv(\"POSTGRESQL_PASSWORD\", \"\")\nDATABASE = os.getenv(\"DATABASE\", \"\")\nDATABASE_URL = os.getenv(\"POSTGRESQL_DATABASE_URL\", \"\")\n</code></pre> <p>3. Create function to connect to postgres database in <code>database_manager.py</code> file:</p> <pre><code>def get_postgres_url():\n    url = urlparse(Postgre_string)\n    # Replace path with '/postgres'\n    new_url = url._replace(path=\"/postgres\")\n    return urlunparse(new_url)\n</code></pre> <p>4. Create Databases function</p> <ul> <li>The system will connect to the 'postgres' database under postgres user and create the required databases listed in <code>REQUIRED_DATABASES</code> using following code in <code>database_manager.py</code> file.</li> </ul> <pre><code>async def check_and_create_databases():\n    conn = await asyncpg.connect(get_postgres_url())\n    try:\n        for db_name in REQUIRED_DATABASES:\n            exists = await conn.fetchval(\n                \"SELECT 1 FROM pg_database WHERE datname = $1\", db_name\n            )\n            if not exists:\n                print(f\"Database '{db_name}' not found. Creating...\")\n                await conn.execute(f'CREATE DATABASE \"{db_name}\"')\n            else:\n                print(f\"Database '{db_name}' already exists.\")\n    finally:\n        await conn.close()\n</code></pre>"},{"location":"Definitions/Vocabulary%20-%20Definitions/","title":"Vocabulary - Definitions","text":""},{"location":"Definitions/Vocabulary%20-%20Definitions/#what-is-an-ai-agent","title":"What is an AI Agent?","text":"<p>An AI agent is an autonomous entity that can perceive its environment and take actions to achieve specific goals. </p> <p></p> <p>Tools/Skills External functionalities that an AI agent can leverage to perform specific tasks. These extend the agent's capabilities beyond language understanding, enabling it to execute actions and interact with external systems effectively.</p> <p>Other Agents (Integrations/Interfaces) Interfaces or connections with other AI agents or systems. These enable collaboration, task delegation, and seamless integration within a multi-agent ecosystem or with external applications.</p> <p>Actions (Large Action Models) Predefined or dynamically learned complex operations that the agent can execute to achieve specific objectives or respond to user queries.</p> <p>Environment (Context/Prediction) The external state or data that the agent perceives and reacts to. This allows the agent to adapt its behavior dynamically based on real-time context or changing scenarios.</p> <p>Planning (Reasoning) The cognitive process of determining the next steps based on goals, environmental inputs, and memory. Planning drives the logical sequencing of actions and tool usage to accomplish tasks efficiently and effectively.</p> <p>Goals The objectives or desired outcomes defined for or by the agent. These guide the agent's decision-making and planning processes, ensuring its behavior aligns with its mission or user expectations.</p> <p>User (Feedback) Human users who interact with the agent and provide feedback, corrections, or instructions. This feedback helps refine the agent's responses and ensures alignment with user needs and expectations.</p> <p>Memory (Short and Long) The storage of past interactions or knowledge, categorized as: - Short Term Memory: Temporary context retained during the current conversation or session. - Long Term Memory: Persistent data stored across sessions, enabling the agent to maintain continuity and personalization over time.</p> <p>Agent (Core LLM) The central decision-making entity, typically powered by a large language model (LLM). It performs natural language understanding, reasoning, and orchestrates all other components to complete tasks and provide meaningful responses.</p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#key-components-of-an-agent","title":"Key Components of an Agent \u200b","text":"<p>LLM The brain of the agent that interprets instructions from humans or other agents, plans actions, or evaluates alternatives.</p> <p>Memory This where instructions, feedback, external stimulus and states are stored.</p> <p>Integrations/ Interface Agents need to communicate with other agents, humans or LLms to pass on messages, prompts, feedback and instructions.</p> <p>Adaptive Agents adapt and learn dynamically from the real time environment and adjust their actions.</p> <p>Skills and Tools This is the device like web-browser, fill forms, use other applications(API's) tools like OCR, image generators, social media plugins etc. to take real life actions.</p> <p>Reasoning Capabilities Different additional frameworks like Chain/Graph of thoughts, RAG Setups, vector DBs are needed to augment performance.</p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#roles-of-an-agent","title":"Roles of an Agent","text":"<p>AI agents can adopt a wide range of roles based on the task, domain, and context in which they are deployed. These roles showcase the adaptability and functional versatility of intelligent agents, making them valuable across both business and technical environments.</p> <p></p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#react-agent","title":"React Agent","text":"<p>The ReAct(Reasoning and Acting) agent combines reasoning traces with action execution. It uses a step by step thought process to determine what tool to use, executes it, observe the result, and continues until it can return a final answer.</p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#multi-agent","title":"Multi Agent","text":"<p>The Multi Agent operates on the Planner-Executor-Critic paradigm. It begins with a Planner Agent that generates a step-by-step plan based on the user query. The Executor Agent then executes each step of the plan. The Critic evaluates the outputs by scoring the results of each step.</p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#planner-agent","title":"Planner Agent","text":"<p>The Planner Agent is responsible for creating a detailed, step-by-step plan to achieve a given objective or respond to a user query. It interprets the user's instructions, breaks them down into actionable steps, and presents the plan for review or execution. This ensures clarity, structure, and alignment with the desired outcome.</p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#executor-agent","title":"Executor Agent","text":"<p>The Executor Agent is responsible for carrying out the steps outlined by the Planner Agent. It executes each step in the plan. The Executor Agent ensures that actions are performed accurately and efficiently, adapting to any changes or feedback during execution to achieve the desired outcome.</p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#critic-agent","title":"Critic Agent","text":"<p>The Critic Agent evaluates the outputs generated during the execution process. It assigns a score to each result based on predefined criteria or thresholds. If the score meets or exceeds the threshold, the Critic Agent finalizes the response and presents it to the user. If the score falls below the threshold, the Critic Agent triggers internal adjustments or refinements to improve the output, ensuring the final response is accurate and aligned with user expectations.</p>"},{"location":"Definitions/Vocabulary%20-%20Definitions/#meta-agent","title":"Meta Agent","text":"<p>Serves as the central decision making entity. Individual agents are coordinated by a central supervisor agent. The supervisor controls all communication flow and task delegation, making decisions about which agent to invoke based on the current context and task requirements.</p>"},{"location":"Definitions/hitl/","title":"Human Involvement in Agentic Frameworks","text":"<p>Human-in-the-loop (HITL) is a system design approach where human input, oversight, or decision-making is integrated into an automated or AI-driven process to improve accuracy, safety, or control.</p> <p>In the Agentic Foundry Framework, HITL is included as a core element of the Multi Agent, ensuring that humans can guide or intervene in agent behavior when necessary.</p>"},{"location":"Definitions/hitl/#_1","title":"Human in the loop","text":""},{"location":"Definitions/hitl/#overview-human-intervention-in-ai-systems","title":"Overview: Human Intervention in AI Systems","text":"<p>Human intervention refers to the active or passive role a human plays during the lifecycle of an AI or agent system. In our framework, this intervention is integrated at multiple stages:</p> <ul> <li>Design phase: Humans select and configure tools that the agent will use.</li> <li>Execution phase: Humans monitor outputs and provide feedback as needed.</li> <li>Learning phase: Humans review performance and provide examples to refine the agent.</li> </ul> <p>The goal is to combine the speed and efficiency of automation with the contextual understanding, judgment, and oversight that only humans can provide.</p>"},{"location":"Definitions/hitl/#human-in-the-loop-hitl","title":"Human-in-the-Loop (HITL)","text":"<p>In this mode, humans are an essential part of the decision-making process. The agent does not proceed without human input at critical steps. This ensures high accuracy and safety, especially in sensitive or high-stakes domains.</p> <p>Application in the Framework</p> <ul> <li>During inference, the agent may generate a draft response that requires human review before it is finalized and returned.</li> <li>During tool onboarding, the user manually selects or curates data, tools, or prompts.</li> </ul> <p>Typical Use Cases</p> <ul> <li>Domains requiring high precision, such as healthcare or legal advice.</li> <li>Tasks where incorrect or biased outputs could have serious consequences.</li> <li>Content moderation or generation where user approval is required.</li> </ul> <p>Workflow</p> <ol> <li>The user submits a query or task to the agent.</li> <li>The agent generates a preliminary output, such as a step-by-step plan based on the user query. </li> <li>The human reviews the plan and has the option to approve or reject it:<ul> <li>Approve: If the user approves the plan, the agent finalizes the output and returns the answer.</li> <li>Reject: If the user rejects the plan, they provide feedback. The agent uses a replanner mechanism to regenerate a revised plan based on the feedback. </li> </ul> </li> <li>Once the revised plan is approved, the final answer is returned to the user.</li> </ol>"},{"location":"Evaluation/evaluation_metrics/","title":"Evaluation Metrics","text":"<p>Evaluation metrics are essential for assessing the performance and efficiency of AI agents. This document outlines the evaluation metrics used to measure the effectiveness of AI agents, focusing on the LLM as Judge approach.</p>"},{"location":"Evaluation/evaluation_metrics/#llm-as-judge-approach","title":"LLM as Judge Approach","text":"<p>The LLM as Judge approach involves using a large language model (LLM) to evaluate the performance of AI agents. The LLM acts as an impartial evaluator, analyzing the agent's actions, reasoning, and responses based on predefined metrics. This approach ensures a consistent and objective evaluation process.</p>"},{"location":"Evaluation/evaluation_metrics/#evaluation-metrics-workflow","title":"Evaluation metrics workflow","text":"<ul> <li>while inferencing, we are storing the data required for the evaluation in a postgres evaluation_data table with initial status as unprocessed.</li> <li>we have an endpoint - /evaluate, when get hit, it fetches one by one unprocessed records from the evaluation_data table. for each record,<ul> <li>agent evaluation metrics are calculated. </li> <li>if there are any tool calls, tool evaluation metrics are calculated.</li> <li>scores will be stored in agent_evaluation_metrics and tool_evaluation_metrics tables referencing the evaluation_data table respectively.</li> <li>if scores are calculated successfully, the status will be updated as success, otherwise error.</li> </ul> </li> <li>this process is repeated until all the unprocessed records are processed.</li> <li>now, we connect grafana with our tables to display these scores on dashboard.</li> </ul>"},{"location":"Evaluation/evaluation_metrics/#tool-utilization-efficiency","title":"Tool Utilization Efficiency","text":"<p>This metric evaluates how effectively the AI agent selects and uses external tools.</p> Metric Description Tool Selection Accuracy The rate at which the AI chooses the most appropriate tool for a given task. Tool Usage Efficiency A measure of how optimally the AI uses selected tools, considering factors like unnecessary calls and resource usage. Tool Call Precision The accuracy and appropriateness of parameters used in tool calls. Tool Call Success Rate Success rate of the overall tool calls. <p>Overall Score: The overall score for Tool Utilization Efficiency is based on the scores of the evaluation metrics above.</p>"},{"location":"Evaluation/evaluation_metrics/#agents-efficiency-score","title":"Agents Efficiency Score","text":"<p>This metric measures the efficiency of the agentic workflow.</p> Metric Description Task Decomposition Efficiency The AI's ability to break down complex tasks into manageable sub-tasks. Reasoning Relevancy Ensures the agent\u2019s reasoning aligns with the user query. Is the reasoning behind each tool call clearly tied to what the user is asking for? Reasoning Coherence Checks the logical flow in the agent\u2019s reasoning. Does the reasoning follow a logical, step-by-step process? Each step should add value and make sense in the context of the task. Agent Robustness Measures the ability of the AI agent to handle unexpected inputs, errors, and adversarial scenarios while maintaining performance and reliability. Agent Consistency Measures the AI agent's ability to produce stable, repeatable, and logically coherent responses across multiple interactions with similar inputs. Answer Relevance Checks if the answer is relevant to the input. Groundedness Evaluates how well the agent\u2019s responses are anchored in factual, verifiable, and contextually relevant sources, minimizing hallucination and misinformation. Response Fluency Assesses the readability, grammatical correctness, and naturalness of the agent\u2019s responses. Response Coherence Measures whether the agent's response is logically structured and maintains clarity throughout the conversation. <p>Overall Score: The overall score for Agents Efficiency Score is based on the scores of the evaluation metrics above.</p>"},{"location":"Evaluation/evaluation_metrics/#filters-in-evaluation-metrics-for-agents-and-tools","title":"Filters in Evaluation Metrics for Agents and Tools","text":"<p>The evaluation metrics system allows you to apply a variety of filters to analyze and visualize performance data. These filters include:</p> <ul> <li>Filter by Agent Type: Isolate metrics for specific types of agents (e.g., multi agent, react agent).</li> <li>Filter by Model Used by Agent: Focus on specific models deployed by the agents (e.g., GPT-4, GPT-4o-3, etc.).</li> <li>Filter by Evaluating Model: Filter metrics based on the model performing the evaluation.</li> <li>Filter by Agent Name: Filter by individual agent names for more granular analysis (e.g, Calculator agent, Greet, etc.).</li> </ul> <p>These filters facilitate the creation of both Agent-Level and Tool-Level evaluation graphs, helping to visualize the metrics based on the selected criteria.</p> <p>Additionally, the evaluation system includes a Threshold Score parameter, which allows you to set the minimum score required to include data in the visualization. By default, the threshold_score is set to 1, but you can adjust it to 0, 0.5 for different visualization perspectives. The threshold score modification will impact the data displayed in the graphs and can be used to fine-tune the results for better insights.</p> <p>Below are example images showcasing Agent-Level Evaluation and Tool-Level Evaluation with the above-mentioned filters applied. These visualizations offer an intuitive representation of performance based on the selected criteria.</p>"},{"location":"Evaluation/evaluation_metrics/#agent-level-evaluation","title":"Agent-Level Evaluation","text":"<ol> <li>Agent Type Filter Visualization: </li> <li>Model Used by Agent Filter Visualization: </li> <li>Evaluating Model Filter Visualization: </li> <li>Agent Name Filter Visualization: </li> </ol>"},{"location":"Evaluation/evaluation_metrics/#tool-level-evaluation","title":"Tool-Level Evaluation","text":"<ol> <li>Agent Type Filter Visualization: </li> <li>Model Used by Tool Filter Visualization: </li> <li>Evaluating Model Filter for Tools Visualization: </li> <li>Agent Name Filter Visualization: </li> </ol>"},{"location":"Inference/inference/","title":"Inference","text":""},{"location":"Inference/inference/#what-is-inference","title":"What is Inference?","text":"<p>Inference is the section where you can interact with the agents you have created through a chat interface. It allows you to select and model, initiate a conversation, and observe how the agent responds bsed on its reasoning.</p> <p></p>"},{"location":"Inference/inference/#steps-to-onboard-agent-in-inference","title":"Steps to onboard Agent in InferenceStep 1: Select an Agent TypeStep 2: Select a Model TypeStep 3: Select the Agent","text":"<p>This guide walks you through the steps required to run an inference using our framework.</p> <p>From the dropdown menu, choose the agent type.</p> <p>Available Agent Types:</p> <ul> <li>React Agent</li> <li>Multi Agent</li> <li>Meta Agent</li> <li>Custom Agent </li> </ul> <p>After selecting the agent type, pick a model type that the agent will use.</p> <p>Available Model Types:</p> <ul> <li>GPT4-8k</li> <li>GPT-4o-mini</li> <li>GPT-4o</li> <li>GPT-4o-2</li> <li>GPT-4o-3</li> <li>Gemini-1.5-Flash</li> </ul> <p></p> <p>Finally, choose the specific agent from the dropdown.</p> <p></p>"},{"location":"Inference/inference/#react-agent-inference","title":"React Agent Inference","text":"<p>React Agent The React Agent inference is a simple chat window where you can chat with the agent you have onboarded and can see the steps taken by the agent to answer your queries.</p>"},{"location":"Inference/inference/#multi-agent-inference","title":"Multi Agent Inference","text":"<p>Multi Agent In the Multi Agent Inference setup, we offer a Human-in-the-Loop option. This feature allows users to review and approve each step the agent plans to execute before it proceeds. </p>"},{"location":"Inference/inference/#meta-agent-inference","title":"Meta Agent Inference","text":"<p>Meta Agent The Meta Agent inference offers a chat interface similar to the React Agent. It allows you to interact with the onboarded agent and view the steps it takes to process your queries, providing transparency into its decision-making process.</p>"},{"location":"Inference/metaAgent_inference/","title":"Meta Agent Inference","text":"<p>The Meta Agent inference setup provides a simple chat interface where you can interact with the onboarded agent and observe the steps it takes to answer your queries.</p> <p>Meta Agent Inference Window: </p> <p>Select the Meta Agent template, model, and agent name to begin interacting with the agent. </p>"},{"location":"Inference/metaAgent_inference/#examples-of-chat-screens-for-a-movie_and_scholar_agent","title":"Examples of Chat Screens for a Movie_and_scholar_AgentInference Results","text":"<p>Below is the sample chat interaction showcasing the inference process:</p> <p> </p>"},{"location":"Inference/metaAgent_inference/#steps-taken-by-the-agent","title":"Steps Taken by the Agent","text":"<ul> <li>You can view the steps taken by the agent to answer your query by clicking the \"Steps\" dropdown.  </li> <li>These steps reveal the agents the meta agent calls based on the user query, providing transparency into the decision-making process.</li> </ul>"},{"location":"Inference/metaAgent_inference/#retrieving-old-chats","title":"Retrieving Old Chats","text":"<ul> <li>Retrieve your old chats by selecting them from the \"Old Chats\" dropdown.</li> <li>This feature allows you to revisit previous conversations with the agent for reference or analysis.</li> </ul>"},{"location":"Inference/multiAgent_inference/","title":"Multi Agent Inference","text":"<p>In the Multi Agent Inference setup, we offer a Human-in-the-Loop option. This feature allows users to review and approve each step the agent plans to execute before it proceeds. It ensures greater control, transparency and safety during the agent's decision-making process.</p> <p></p>"},{"location":"Inference/multiAgent_inference/#inference-with-human-in-the-loop","title":"Inference with Human in the Loop","text":"<p>Toggling on the Human-in-the-Loop button, invokes the agent to provide a detailed plan about the steps it will perform to execute the tasks. </p> <p> </p> <p>After the agent provides the plan, it will ask for your approval or your feedback.</p> <p></p> <p>The thumbs-up button is the approval button. Clicking on this button, you will approve the plan proposed by the agent and the agent will execute your query. </p> <p></p> <p>The thumbs-down button is the feedback button. Clicking on the button, will ask you to provide your feedback for the plan generated by the agent. The agent will regenerate the plan according to your feedback.</p> <p></p> <p>You can see the critic score of the response by clicking the \"Steps\" dropdown.</p> <p></p>"},{"location":"Inference/reactAgent_inference/","title":"React Agent Inference","text":"<p>The React Agent inference setup provides a simple chat interface where you can interact with the onboarded agent and observe the steps it takes to answer your queries.</p>"},{"location":"Inference/reactAgent_inference/#examples-of-chat-screens-for-a-weather-agent","title":"Examples of Chat Screens for a Weather AgentInference Results","text":"<p>Below are sample chat interactions showcasing the inference process:</p> <p> </p>"},{"location":"Inference/reactAgent_inference/#steps-taken-by-the-agent","title":"Steps Taken by the Agent","text":"<ul> <li>You can view the steps taken by the agent to answer your query by clicking the \"Steps\" dropdown.  </li> <li>These steps reveal the tools the agent calls based on the user query, providing transparency into the decision-making process.</li> </ul>"},{"location":"Inference/reactAgent_inference/#retrieving-old-chats","title":"Retrieving Old Chats","text":"<ul> <li>Retrieve your old chats by selecting them from the \"Old Chats\" dropdown.</li> <li>This feature allows you to revisit previous conversations with the agent for reference or analysis.</li> </ul>"},{"location":"Installation/Azure/","title":"Project Setup Guide","text":"<p>This document provides comprehensive step-by-step instructions to set up and run the project on your local machine and deploy it to Azure VM.</p>"},{"location":"Installation/Azure/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have the following installed on your system:</p> <ol> <li>Python (version 3.8 or higher)</li> <li>pip (Python package manager)</li> <li>Virtual Environment Support (comes pre-installed with Python 3.3+)</li> <li>Streamlit and Uvicorn dependencies (will be installed during setup)</li> </ol>"},{"location":"Installation/Azure/#local-development-setup","title":"Local Development Setup","text":"<p>Step 1: Create a Virtual Environment</p> <p>A virtual environment is used to isolate project dependencies. Run the following command in the terminal or command prompt:</p> <pre><code>python -m venv .venv\n</code></pre> <p>This will create a virtual environment named <code>.venv</code> in the project directory.</p> <p>Step 2: Activate the Virtual Environment</p> <p>To activate the virtual environment, use the appropriate command for your operating system:</p> <p>For Windows :</p> <pre><code>.\\.venv\\Scripts\\activate\n</code></pre> <p>For macOS/Linux</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Note</p> <p>Once activated, your terminal prompt will change to indicate the virtual environment is active.</p> <p>Step 3: Install Project Dependencies</p> <p>After activating the virtual environment, install the required dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>This will install all the libraries and packages listed in the <code>requirements.txt</code> file.</p> <p>Step 4: Run the Backend Server</p> <p>To start the backend server, ensure the virtual environment is active and run:</p> <pre><code>uvicorn agentic_workflow_as_service_endpoints:app --host 0.0.0.0 --port 8000 --workers 4\n</code></pre> <p>Command Explanation:</p> <ul> <li><code>uvicorn</code>: A lightweight ASGI server</li> <li><code>agentic_workflow_as_service_endpoints:app</code>: Refers to the Python module and the FastAPI app instance</li> <li><code>--host 0.0.0.0</code>: Makes the server accessible from any network interface</li> <li><code>--port 8000</code>: Specifies the port on which the server will run</li> <li><code>--workers 4</code>: Specifies the number of worker processes to handle requests</li> </ul> <p>Success</p> <p>The backend server will start and be accessible at: - <code>http://0.0.0.0:8000</code> (local access) - <code>http://&lt;your-local-ip&gt;:8000</code> (network access)</p> <p>Step 5: Run the User Interface</p> <p>To launch the user interface, ensure the virtual environment is active and execute:</p> <pre><code>streamlit run user_interface.py --server.port 8501 --server.address 0.0.0.0\n</code></pre> <p>Command Explanation:</p> <ul> <li><code>streamlit</code>: A Python library for building web-based user interfaces</li> <li><code>user_interface.py</code>: The script containing the Streamlit application</li> <li><code>--server.port 8501</code>: Specifies the port for the Streamlit app</li> <li><code>--server.address 0.0.0.0</code>: Makes the app accessible from any network interface</li> </ul> <p>Info</p> <p>The Streamlit app will open in your default web browser automatically. If not, access it at: - <code>http://0.0.0.0:8501</code> (local access) - <code>http://&lt;your-local-ip&gt;:8501</code> (network access)</p>"},{"location":"Installation/Azure/#azure-vm-deployment","title":"Azure VM Deployment","text":"<p>Prerequisites for Azure Deployment</p> <ol> <li>Valid Azure Subscription</li> <li>CCD Request for Azure Windows VM resource</li> <li>Required Software(to be installed on Azure VM):<ul> <li>Python 3.12 or above (avoid latest unstable versions)</li> <li>VS Code</li> <li>GitBash (if required)</li> <li>NSSM (for service management)</li> </ul> </li> </ol> <p>Deployment Steps</p> <p>Step 1: Azure VM Setup</p> <ol> <li>Request a valid Azure Subscription</li> <li>Raise a CCD request to add an Azure Windows VM resource</li> <li>Wait for CCD team to create the VM resource and share credentials</li> <li>Install required software on Azure VM:</li> <li>Use CCD team assistance, or</li> <li>Install locally and transfer via \"infydrive\"</li> </ol> <p>Step 2: Application Deployment</p> <ol> <li>Move your application folder to Azure VM</li> <li>Follow Steps 1-5 from the Local Development Setup section</li> <li>Verify application accessibility from outside the VM by sharing network URL with external users</li> </ol> <p>Warning</p> <p>At this stage, the application will only remain active while the Azure VM is running. VM shutdown will cause application downtime.</p>"},{"location":"Installation/Azure/#how-to-make-the-server-run-247-on-windows-using-nssm","title":"How to Make the Server Run 24/7 on Windows Using NSSM","text":"<p>Step 1: Create a Batch File</p> <p>Create a new file named <code>servers.bat</code> (you can choose any name).</p> <p>Paste the following content into the file:</p> <pre><code>@echo off\nREM Activate Python virtual environment\ncd /d \"C:\\Code\\Infyagentframework-main\\Infyagentframework-main\\.venv\\Scripts\"\ncall activate.bat\n\nREM Change to project directory\ncd /d \"C:\\Code\\Infyagentframework-main\\Infyagentframework-main\\backend\"\n\nREM Start FastAPI backend\nstart cmd /k \"uvicorn agentic_workflow_as_service_endpoints:app --host 0.0.0.0 --port 8000 --workers 4\"\n\nREM Start Node.js frontend\ncd /d \"C:\\Code\\Agentic-Pro-UI\\frontend\"\nstart cmd /k \"npm start\"\n\npause\n</code></pre> <p>Important</p> <p>Make sure the file paths match your system's folder structure.</p> <p>Tip</p> <p>Save the file somewhere accessible, like your desktop or project root.</p> <p>Step 2: Install and Configure NSSM</p> <ol> <li>Download NSSM if not already installed: https://nssm.cc/download</li> <li>Open Command Prompt as Administrator.</li> <li>Run this command to open the NSSM setup:</li> </ol> <pre><code>nssm install infy_agent.service\n</code></pre> <p>Custom Service Name</p> <p>You can replace <code>infy_agent.service</code> with any name you prefer, such as <code>my_server_service</code>, <code>webstack_service</code>, or <code>custom_backend</code>. Just make sure to use the same name consistently in all subsequent commands.</p> <ol> <li>In the NSSM GUI:</li> <li>For Application path, browse and select your <code>servers.bat</code> file.</li> <li>Click Install Service.</li> </ol> <p>Step 3: Manage the Service</p> <p>Use these commands from the terminal (as Administrator):</p> <p>Start the service:</p> <pre><code>nssm start infy_agent.service\n</code></pre> <p>Stop the service:</p> <pre><code>nssm stop infy_agent.service\n</code></pre> <p>Edit the service:</p> <pre><code>nssm edit infy_agent.service\n</code></pre> <p>You can also go to Windows Services (press <code>Win + R</code>, type <code>services.msc</code>) to start, stop, or set the service to run automatically on startup.</p>"},{"location":"Installation/Azure/#troubleshooting","title":"Troubleshooting","text":"<p>Virtual Environment Activation Fails</p> <ul> <li>Windows: Ensure you're using the correct command for your OS</li> <li>Permissions Error: Try running command prompt as administrator</li> </ul> <p>Dependency Installation Errors</p> <p>Update pip to the latest version:</p> <pre><code>python -m pip install --upgrade pip\n</code></pre> <p>Server or UI Not Starting</p> <ol> <li>Verify the virtual environment is active</li> <li>Check for typos in commands or file names</li> <li>Ensure all dependencies are properly installed</li> </ol>"},{"location":"Installation/Azure/#additional-notes","title":"Additional Notes","text":"<p>Best Practices</p> <ul> <li>Always activate the virtual environment before running project commands</li> <li>Verify all dependencies are installed correctly by checking <code>requirements.txt</code></li> <li>To deactivate the virtual environment, simply run: <code>deactivate</code></li> </ul>"},{"location":"Installation/linux/","title":"Linux VM Deployment Guide","text":"<p>This guide provides detailed instructions for setting up and running the FastAPI backend and React frontend project on Linux Virtual Machines.</p>"},{"location":"Installation/linux/#project-overview","title":"Project Overview","text":"<p>This project consists of a backend server built with FastAPI and a frontend interface using React, designed for deployment on Linux VMs.</p>"},{"location":"Installation/linux/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the following installed on your Linux system:</p> <p>System Requirements</p> <ul> <li>sudo privileges (for installing system packages)</li> <li>Python 3.11 or higher (for backend)</li> <li>NodeJS version 22 or higher </li> <li>NPM version 10.9.2 or higher ( comes bundled with NodeJs) </li> <li>Git (optional, for cloning the repository)</li> </ul>"},{"location":"Installation/linux/#python-version-setup","title":"Python Version Setup","text":"<p>Check Your Python Version</p> <p>First, verify your current Python version:</p> <pre><code>python --version\n# or\npython3 --version\n</code></pre> <p>Make sure it is 3.11 or higher. If it's not, you'll need to update your Python version.</p> <p>Python Installation Options</p> <p>There are 2 ways to install the required Python version:</p> <ol> <li>Install from CCD - Install a required greenlisted Python version</li> <li>Use pyenv - Update the Python version using pyenv (recommended)</li> </ol>"},{"location":"Installation/linux/#installing-python-with-pyenv-on-rhel","title":"Installing Python with pyenv on RHEL","text":"<p>To install pyenv on Red Hat Enterprise Linux (RHEL), follow these steps. pyenv lets you easily install and switch between multiple Python versions.</p> <p>Step 1: Install Required Dependencies</p> <p>You'll need development tools and libraries for building Python:</p> <pre><code>sudo dnf groupinstall \"Development Tools\" -y\nsudo dnf install -y \\\n    gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel \\\n    openssl-devel libffi-devel wget make xz-devel \\\n    git curl patch\n</code></pre> <p>Step 2: Install pyenv</p> <p>Clone the pyenv repository into your home directory:</p> <pre><code>git clone https://github.com/pyenv/pyenv.git ~/.pyenv\n</code></pre> <p>Step 3: Set Up Shell Environment</p> <p>Add the following to your shell config file (e.g., <code>~/.bashrc</code>, <code>~/.bash_profile</code>, or <code>~/.zshrc</code>):</p> <pre><code>export PYENV_ROOT=\"$HOME/.pyenv\"\nexport PATH=\"$PYENV_ROOT/bin:$PATH\"\neval \"$(pyenv init --path)\"\neval \"$(pyenv init -)\"\n</code></pre> <p>Then apply the changes:</p> <pre><code>source ~/.bashrc\n# or\nexec \"$SHELL\"\n</code></pre> <p>Step 4: Verify Installation</p> <p>Run the following command to verify pyenv is installed correctly:</p> <pre><code>pyenv --version\n</code></pre> <p>Step 5: Install Python Version</p> <p>Install the required Python version (example with Python 3.11.8):</p> <pre><code>pyenv install 3.11.8\n</code></pre> <p>You can also install other versions as needed:</p> <pre><code># List available Python versions\npyenv install --list\n\n# Install specific version\npyenv install 3.12.0\n</code></pre> <p>Step 6: Set Global Python Version</p> <p>Set the installed Python version as your global default:</p> <pre><code>pyenv global 3.11.8\n</code></pre> <p>Verify the installation:</p> <pre><code>python --version\n</code></pre> <p>Verify Node.js and npm</p> <p>To verify your Node.js and npm installations, open Terminal and run:</p> <pre><code>node -v\nnpm -v\n</code></pre> <ul> <li>If Node.js is installed, running the version command will display the installed version.</li> <li>If Node.js is not installed, you will see an error in the terminal such as <code>\"node\" is not recognized as an internal or external command</code>.</li> <li>To install Node.js:<ol> <li>Go to https://nodejs.org/en/download.</li> <li>Choose version 22.16.0 or any higher stable version.</li> <li>Download and install Node.js (NPM comes bundled with Node.js).</li> </ol> </li> <li>After installation, open your command prompt or terminal.</li> <li> <p>Run <code>node -v</code> to confirm that it shows version 22 or higher.</p> </li> <li> <p>JFrog Access for Node Dependencies:</p> <ul> <li>You need JFrog access to download node dependencies for the React UI application.</li> <li>If you already have JFrog access, you can proceed.</li> <li>If not, follow these steps:<ol> <li>Ensure you are connected to the Infosys network or that Zscaler is enabled.</li> <li>Follow the instructions in the guide: NPM \u2013 Install and Publish with JFrog Artifactory SAAS and ZS.</li> <li>(Note: You may skip the 7th step mentioned in that guide.)</li> </ol> </li> </ul> </li> </ul>"},{"location":"Installation/linux/#setting-up-proxy-in-linux-environment-if-required","title":"Setting Up Proxy in Linux Environment (If Required)","text":"<p>If your network requires a proxy to access the internet, follow these steps to set proxy values as environment variables:</p> <p>Steps:</p> <p>Set proxy environment variables temporarily:</p> <pre><code># Replace with your actual proxy server and port\nexport http_proxy=http://your-proxy-server:your-proxy-port\nexport https_proxy=http://your-proxy-server:your-proxy-port\n\n# Example (replace with your actual proxy details):\n# export http_proxy=http://blrproxy.ad.infosys.com:443\n# export https_proxy=http://blrproxy.ad.infosys.com:443\n</code></pre> <p>To make proxy settings permanent, add to your shell profile:</p> <pre><code># Replace with your actual proxy server and port\necho 'export http_proxy=http://your-proxy-server:your-proxy-port' &gt;&gt; ~/.bashrc\necho 'export https_proxy=http://your-proxy-server:your-proxy-port' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>Note</p> <p>\ud83d\udca1 Always verify proxy details with your CCD or VM administrator and replace the example values with your actual proxy configuration.</p>"},{"location":"Installation/linux/#download-the-backend-project-code","title":"Download the Backend Project Code","text":"<ul> <li> <p>To access the Agentic Foundry GitHub repository, you must have access to InfyGit.</p> </li> <li> <p>If you already have InfyGit access, click the link below and authenticate to gain access to the Agentic Foundry GitHub repository.  https://github.com/enterprises/infosys/sso</p> </li> </ul> <p>You can obtain the project files using one of the following methods:</p> <p>Option 1: Clone Using Git</p> <pre><code>git clone https://github.com/Infosys-Generative-AI/Infyagentframework\ncd Infyagentframework\n</code></pre> <p>Option 2: Download Zip from GitHub</p> <ol> <li>Navigate to: https://github.com/Infosys-Generative-AI/Infyagentframework</li> <li>Click \"Code\" \u2192 \"Download Zip\"</li> <li>Extract to your preferred location</li> </ol> <p>Transferring Files to Linux VM (if needed)</p> <p>If transferring from another machine, use SCP:</p> <pre><code># Replace with your actual username, VM IP address, and file paths\nscp -r /path/to/your/local/project your-username@your-vm-ip-address:/home/your-username/\n\n# Example:\n# scp -r /Users/john/Infyagentframework projadmin@192.168.1.100:/home/projadmin/\n</code></pre>"},{"location":"Installation/linux/#backend-setup","title":"Backend Setup","text":"<p>Setting Up the Backend Environment</p> <ol> <li>Navigate to Backend Directory:</li> </ol> <pre><code>cd backend\n</code></pre> <ol> <li>Create a Virtual Environment:</li> </ol> <pre><code>python3 -m venv .venv\n</code></pre> <ol> <li>Activate the Virtual Environment:</li> </ol> <pre><code>source ./.venv/bin/activate\n</code></pre> <ol> <li>Install Backend Dependencies:</li> </ol> <pre><code>pip install -r requirements.txt\n</code></pre> <p>If you face any SSL error issue, use the below command:</p> <pre><code>pip install -r requirements.txt --trusted-host pypi.org --trusted-host files.pythonhosted.org\n</code></pre>"},{"location":"Installation/linux/#frontend-setup","title":"Frontend Setup","text":"<p>Setup on Linux VM</p> <ol> <li>Navigate to Frontend Directory:</li> </ol> <pre><code>cd frontend\n</code></pre> <ol> <li>Remove Existing Lock File (if present):</li> </ol> <pre><code>rm -f package-lock.json\n</code></pre> <ol> <li>Install Node Modules:</li> </ol> <pre><code>npm install\n</code></pre> <p>If you encounter proxy issues during npm install, configure npm proxy:</p> <pre><code># Replace with your actual proxy server and port\nnpm config set proxy http://your-proxy-server:your-proxy-port\nnpm config set https-proxy http://your-proxy-server:your-proxy-port\n\n# Then run npm install\nnpm install\n</code></pre> <ol> <li>Configure Port and Host in <code>package.json</code>:</li> </ol> <p>Edit <code>package.json</code> to configure the development server:</p> <pre><code>\"scripts\": {\n  \"start\": \"PORT=your-frontend-port HOST=0.0.0.0 react-scripts start\",\n  \"build\": \"PORT=your-frontend-port HOST=0.0.0.0 react-scripts build\"\n}\n</code></pre> <p>Example configuration:</p> <pre><code>\"scripts\": {\n  \"start\": \"PORT=6002 HOST=0.0.0.0 react-scripts start\",\n  \"build\": \"PORT=6002 HOST=0.0.0.0 react-scripts build\"\n}\n</code></pre> <ol> <li>Open Firewall Ports:</li> </ol> <pre><code># Replace with your actual frontend and backend port numbers\nsudo firewall-cmd --permanent --add-port=your-frontend-port/tcp\nsudo firewall-cmd --permanent --add-port=your-backend-port/tcp\n\n# Example with default ports:\n# sudo firewall-cmd --permanent --add-port=6002/tcp  # Frontend\n# sudo firewall-cmd --permanent --add-port=8000/tcp  # Backend\n\n# Reload firewall\nsudo firewall-cmd --reload\n\n# Verify ports are open\nsudo firewall-cmd --list-ports\n</code></pre>"},{"location":"Installation/linux/#configuration-setup","title":"Configuration Setup","text":"<p>Frontend-Backend Connection Configuration: Configure Frontend to Connect to Backend</p> <ol> <li>Edit Constants File:</li> </ol> <pre><code>nano frontend/src/constants.js\n</code></pre> <ol> <li>Update BASE_URL:</li> </ol> <pre><code>// Replace with your actual backend server IP address and port\nexport const BASE_URL = \"http://your-backend-server-ip:your-backend-port\";\n\n// Examples:\n// export const BASE_URL = \"http://192.168.1.100:8000\";\n// export const BASE_URL = \"http://10.0.0.50:8000\";\n// export const BASE_URL = \"http://localhost:8000\";  // If frontend and backend are on same machine\n</code></pre> <p>Configure Backend CORS Settings</p> <p>Update the backend server file (typically <code>agentic_workflow_as_service_endpoints.py</code>):</p> <pre><code>origins = [\n    # Replace with your actual frontend server IP and port\n    \"http://your-frontend-server-ip:your-frontend-port\",\n    \"http://localhost:3000\",\n    \"http://localhost:6002\",\n    # Add additional origins as needed\n]\n\n# Examples:\n# origins = [\n#     \"http://192.168.1.101:6002\",\n#     \"http://10.0.0.51:6002\",\n#     \"http://localhost:3000\",\n#     \"http://localhost:6002\",\n# ]\n</code></pre>"},{"location":"Installation/linux/#environment-configuration","title":"Environment Configuration","text":"<p>Backend Environment Variables</p> <p>Create <code>.env</code> file in backend directory:</p> <pre><code>nano backend/.env\n</code></pre> <p>Add the following content (replace with your actual values):</p> <pre><code>DEBUG=False\n# Replace with your actual API keys and configuration\nAPI_KEY=your_actual_api_key_here\nDATABASE_URL=your_database_url_here\nSECRET_KEY=your_secret_key_here\n\n# Example:\n# API_KEY=sk-1234567890abcdef\n# DATABASE_URL=postgresql://user:password@localhost/dbname\n# SECRET_KEY=your-super-secret-key-here\n</code></pre> <p>Frontend Environment Variables</p> <p>Create <code>.env</code> file in frontend directory:</p> <pre><code>nano frontend/.env\n</code></pre> <p>Add the following content:</p> <pre><code># Replace with your actual backend IP address and port\nREACT_APP_API_URL=http://your-backend-ip:your-backend-port\nREACT_APP_API_TIMEOUT=30000\n\n# Examples:\n# REACT_APP_API_URL=http://192.168.1.100:8000\n# REACT_APP_API_URL=http://10.0.0.50:8000\n# REACT_APP_API_URL=http://localhost:8000\n</code></pre>"},{"location":"Installation/linux/#running-the-applications","title":"Running the Applications","text":"<p>Start the Backend Server</p> <p>With the virtual environment activated:</p> <pre><code>cd backend\n# Replace port number if using a different backend port\nuvicorn agentic_workflow_as_service_endpoints:app --host 0.0.0.0 --port your-backend-port --workers 4\n\n# Example:\n# uvicorn agentic_workflow_as_service_endpoints:app --host 0.0.0.0 --port 8000 --workers 4\n</code></pre> <p>Start the Frontend</p> <pre><code>cd frontend\nnpm start\n</code></pre> <p>The React UI will be accessible at: - <code>http://your-vm-ip:your-frontend-port</code> - Example: <code>http://192.168.1.101:6002</code></p>"},{"location":"Installation/linux/#accessing-the-applications","title":"Accessing the Applications","text":"<p>Frontend Access URLs:</p> <ul> <li>Local access: <code>http://localhost:your-frontend-port</code></li> <li>Network access: <code>http://your-vm-ip:your-frontend-port</code></li> <li>Example: <code>http://192.168.1.101:6002</code></li> </ul> <p>Backend API Access URLs:</p> <ul> <li>Local access: <code>http://localhost:your-backend-port</code></li> <li>Network access: <code>http://your-vm-ip:your-backend-port</code></li> <li>Example: <code>http://192.168.1.100:8000</code></li> <li>API Documentation: <code>http://your-vm-ip:your-backend-port/docs</code></li> </ul>"},{"location":"Installation/linux/#service-deployment","title":"Service Deployment","text":"<ul> <li>Running as System Services</li> </ul> <p>Backend Service</p> <p>Create systemd service file:</p> <pre><code>sudo nano /etc/systemd/system/infyagent-backend.service\n</code></pre> <p>Add content (replace placeholders with your actual values):</p> <pre><code>[Unit]\nDescription=FastAPI Application with Gunicorn\nAfter=network.target\n\n[Service]\n# Replace with your actual project path\nWorkingDirectory=/home/your-username/your-project-directory/backend\n# Replace with your actual paths, username, and port\nExecStart=/home/your-username/your-project-directory/backend/.venv/bin/python -m gunicorn agentic_workflow_as_service_endpoints:app \\\n  --workers 1 \\\n  --worker-class uvicorn.workers.UvicornWorker \\\n  --bind 0.0.0.0:your-backend-port\nRestart=always\n# Replace with your actual username\nUser=your-username\n# Replace with your actual proxy settings (remove if not using proxy)\nEnvironment=\"http_proxy=http://your-proxy-server:your-proxy-port\"\nEnvironment=\"https_proxy=http://your-proxy-server:your-proxy-port\"\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Example configuration:</p> <pre><code>[Unit]\nDescription=FastAPI Application with Gunicorn\nAfter=network.target\n\n[Service]\nWorkingDirectory=/home/projadmin/Infyagentframework/backend\nExecStart=/home/projadmin/Infyagentframework/backend/.venv/bin/python -m gunicorn agentic_workflow_as_service_endpoints:app \\\n  --workers 1 \\\n  --worker-class uvicorn.workers.UvicornWorker \\\n  --bind 0.0.0.0:8000\nRestart=always\nUser=projadmin\nEnvironment=\"http_proxy=http://blrproxy.ad.infosys.com:443\"\nEnvironment=\"https_proxy=http://blrproxy.ad.infosys.com:443\"\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Things You Need to Customize:</p> <ol> <li> <p>Project Path    Replace <code>/home/your-username/your-project-directory/</code> with your actual project path</p> </li> <li> <p>Username    Replace <code>your-username</code> with your actual Linux username</p> </li> <li> <p>Backend Port    Replace <code>your-backend-port</code> with your chosen backend port (e.g., 8000)</p> </li> <li> <p>Proxy Settings    Replace <code>your-proxy-server:your-proxy-port</code> with actual proxy details, or remove if not using proxy</p> </li> <li> <p>App Module Name    Change <code>agentic_workflow_as_service_endpoints:app</code> if your FastAPI app module has a different name</p> </li> </ol> <p>Enable and start the service:</p> <pre><code>sudo systemctl enable infyagent-backend.service\nsudo systemctl start infyagent-backend.service\nsudo systemctl status infyagent-backend.service\n</code></pre> <p>Frontend Service (Optional)</p> <p>Create systemd service file for frontend:</p> <pre><code>sudo nano /etc/systemd/system/infyagent-frontend.service\n</code></pre> <p>Add content:</p> <pre><code>[Unit]\nDescription=React Frontend Application\nAfter=network.target\n\n[Service]\n# Replace with your actual project path\nWorkingDirectory=/home/your-username/your-project-directory/frontend\n# Replace with your actual paths and port\nExecStart=/usr/bin/npm start\nRestart=always\n# Replace with your actual username\nUser=your-username\n# Set environment variables\nEnvironment=NODE_ENV=production\nEnvironment=PORT=your-frontend-port\nEnvironment=HOST=0.0.0.0\n# Replace with your actual proxy settings (if needed)\nEnvironment=\"http_proxy=http://your-proxy-server:your-proxy-port\"\nEnvironment=\"https_proxy=http://your-proxy-server:your-proxy-port\"\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"Installation/linux/#network-configuration","title":"Network Configuration","text":"<p>Port Configuration Summary</p> <p>Default Ports (customize as needed):</p> <ul> <li>Frontend: <code>6002</code> (replace with <code>your-frontend-port</code>)</li> <li>Backend: <code>8000</code> (replace with <code>your-backend-port</code>)</li> </ul> <p>Security Group / Firewall Rules</p> <p>Ensure the following ports are open in your VM's security group or firewall:</p> <pre><code># Replace with your actual port numbers\nsudo firewall-cmd --permanent --add-port=your-frontend-port/tcp\nsudo firewall-cmd --permanent --add-port=your-backend-port/tcp\nsudo firewall-cmd --permanent --add-port=22/tcp  # SSH access\nsudo firewall-cmd --reload\n</code></pre>"},{"location":"Installation/linux/#network-testing","title":"Network Testing","text":"<p>Test connectivity between frontend and backend:</p> <pre><code># Test backend API from frontend server\ncurl http://your-backend-server-ip:your-backend-port/health\n\n# Test frontend access\ncurl http://your-frontend-server-ip:your-frontend-port\n</code></pre>"},{"location":"Installation/linux/#troubleshooting","title":"Troubleshooting","text":"<p>Connection Issues</p> <p>1. Frontend cannot connect to Backend:</p> <ul> <li>Verify <code>BASE_URL</code> in <code>frontend/src/constants.js</code></li> <li>Check CORS settings in backend</li> <li>Ensure backend server is running and accessible</li> <li>Test: <code>curl http://your-backend-ip:your-backend-port/health</code></li> </ul> <p>2. Cannot access applications from external network:</p> <ul> <li>Check firewall rules: <code>sudo firewall-cmd --list-ports</code></li> <li>Verify HOST is set to <code>0.0.0.0</code> (not <code>localhost</code>)</li> <li>Check VM security group settings</li> </ul> <p>Service Issues</p> <p>3. Service fails to start:</p> <ul> <li>Check service logs: <code>sudo journalctl -u infyagent-backend.service -f</code></li> <li>Verify file paths in service configuration</li> <li>Check user permissions</li> <li>Ensure virtual environment is properly configured</li> </ul> <p>Proxy Issues</p> <p>4. Cannot install packages or clone repositories:    - Verify proxy settings: <code>echo $http_proxy</code>    - Check proxy configuration with your administrator    - Test proxy: <code>curl -I http://google.com</code></p> <p>Log Locations</p> <ul> <li>Backend service logs: <code>sudo journalctl -u infyagent-backend.service</code></li> <li>Frontend service logs: <code>sudo journalctl -u infyagent-frontend.service</code></li> <li>System logs: <code>/var/log/messages</code></li> </ul> <p>Maintenance</p> <p>Keep your deployment updated:</p> <pre><code># Update project (if using Git)\ngit pull origin main\n\n# Update backend dependencies\ncd backend\nsource ./.venv/bin/activate\npip install -r requirements.txt\n\n# Update frontend dependencies\ncd frontend\nnpm install\n\n# Restart services after updates\nsudo systemctl restart infyagent-backend.service\nsudo systemctl restart infyagent-frontend.service\n</code></pre>"},{"location":"Installation/linux/#project-structure","title":"Project Structure","text":"<p>The structure shown below is a sample. The full project includes additional files and directories not listed here.</p> <pre><code>Infyagentframework/\n\u251c\u2500\u2500 backend/                  # Backend FastAPI application\n\u2502   \u251c\u2500\u2500 .venv/                # Python virtual environment (generated)\n\u2502   \u251c\u2500\u2500 requirements.txt      # Python dependencies\n\u2502   \u251c\u2500\u2500 .env                  # Environment variables (create this)\n\u2502   \u2514\u2500\u2500 agentic_workflow_as_service_endpoints.py  # Main API file\n\u251c\u2500\u2500 frontend/                 # React frontend application\n\u2502   \u251c\u2500\u2500 node_modules/         # Node.js dependencies (generated)\n\u2502   \u251c\u2500\u2500 public/               # Static assets\n\u2502   \u251c\u2500\u2500 src/                  # React source code\n\u2502   \u2502   \u251c\u2500\u2500 components/       # React components\n\u2502   \u2502   \u251c\u2500\u2500 pages/            # Page components\n\u2502   \u2502   \u251c\u2500\u2500 services/         # API service functions\n\u2502   \u2502   \u251c\u2500\u2500 constants.js      # Configuration constants (update BASE_URL here)\n\u2502   \u2502   \u251c\u2500\u2500 App.js            # Main App component\n\u2502   \u2502   \u2514\u2500\u2500 index.js          # Entry point\n\u2502   \u251c\u2500\u2500 package.json          # Node.js dependencies and scripts (update PORT here)\n\u2502   \u251c\u2500\u2500 package-lock.json     # Lock file for dependencies\n\u2502   \u2514\u2500\u2500 .env                  # Environment variables (create this)\n\u2514\u2500\u2500 README.md                 # Project documentation\n</code></pre> <p>Default Commands with Placeholders:</p> <pre><code># Backend startup\nuvicorn agentic_workflow_as_service_endpoints:app --host 0.0.0.0 --port your-backend-port\n\n# Frontend access\nhttp://your-vm-ip:your-frontend-port\n\n# Backend API access\nhttp://your-vm-ip:your-backend-port/docs\n</code></pre> <p>Remember to replace all placeholder values with your actual IP addresses, ports, usernames, and paths before deployment!</p>"},{"location":"Installation/windows/","title":"Windows Setup Guide","text":"<p>This guide provides step-by-step instructions for setting up and running the project with React UI on a Windows VM (Virtual Machine).</p>"},{"location":"Installation/windows/#project-overview","title":"Project Overview","text":"<p>This project consists of a backend server built with FastAPI and a frontend interface using React. Follow the instructions below to get it up and running on your VM.</p>"},{"location":"Installation/windows/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have the following installed:</p>"},{"location":"Installation/windows/#required-software","title":"Required Software","text":"<ul> <li>Python 3.11 or higher</li> <li>pip (Python package manager)</li> <li>Git (optional, for cloning the repository)</li> <li>A code editor (e.g., VS Code is recommended, but any editor of your choice will work)</li> <li>NodeJS version 22 or above  </li> <li>NPM version 10.9.2 or above ( comes bundled with NodeJs) </li> </ul> <p>To verify your Node.js and npm installations, open Terminal and run:</p> <pre><code>node -v\nnpm -v\n</code></pre> <ul> <li>If Node.js is installed, running the version command will display the installed version.</li> <li>If Node.js is not installed, you will see an error in the terminal such as <code>\"node\" is not recognized as an internal or external command</code>.</li> <li>To install Node.js:<ol> <li>Go to https://nodejs.org/en/download.</li> <li>Choose version 22.16.0 or any higher stable version.</li> <li>Download and install Node.js (NPM comes bundled with Node.js).</li> </ol> </li> <li>After installation, open your command prompt or terminal.</li> <li> <p>Run <code>node -v</code> to confirm that it shows version 22 or higher.</p> </li> <li> <p>JFrog Access for Node Dependencies:</p> <ul> <li>You need JFrog access to download node dependencies for the React UI application.</li> <li>If you already have JFrog access, you can proceed.</li> <li>If not, follow these steps:<ol> <li>Ensure you are connected to the Infosys network or that Zscaler is enabled.</li> <li>Follow the instructions in the guide: NPM \u2013 Install and Publish with JFrog Artifactory SAAS and ZS.</li> <li>(Note: You may skip the 7th step mentioned in that guide.)</li> </ol> </li> </ul> </li> </ul>"},{"location":"Installation/windows/#setting-up-proxy-in-system-environment-variables-if-required","title":"Setting Up Proxy in System Environment Variables (If Required)","text":"<p>If your network requires a proxy to access the internet, follow these steps to set proxy values as system environment variables:</p> <p>Steps:</p> <ol> <li>Open the Start Menu and search for Environment Variables.</li> <li>Click on \"Edit the system environment variables\".</li> <li>In the System Properties window, click on the \"Environment Variables\" button.</li> <li>Under the System variables section, click New.</li> <li>Create the following two variables (ask your VM creator or CCD):</li> </ol> <pre><code>   Variable name: http_proxy\n   Variable value: http://blrproxy.ad.infosys.com:443\n\n   Variable name: https_proxy\n   Variable value: http://blrproxy.ad.infosys.com:443\n</code></pre> <ol> <li>Click OK to save and close all windows.</li> <li>Restart your Command Prompt or system (if needed) for the changes to take effect.</li> </ol> <p>Note</p> <p>\ud83d\udca1 These values are just examples. Always verify proxy details with your CCD or VM administrator.</p>"},{"location":"Installation/windows/#download-the-backend-project-code","title":"Download the Backend Project Code","text":"<ul> <li> <p>To access the Agentic Foundry GitHub repository, you must have access to InfyGit.</p> </li> <li> <p>If you already have InfyGit access, click the link below and authenticate to gain access to the Agentic Foundry GitHub repository.  https://github.com/enterprises/infosys/sso</p> </li> </ul> <p>You can obtain the project files using one of the following methods:</p> <p>Option 1: Clone Using Git</p> <p>If you have Git installed, open Terminal and run:</p> <pre><code>git clone https://github.com/Infosys-Generative-AI/Infyagentframework\ncd Infyagentframework\n</code></pre> <ul> <li>The git clone command will create a new folder named \"Infyagentframework\" in your current directory and download all repository files into it.</li> <li>The cd command navigates into the newly created folder.</li> </ul> <p>Option 2: Download Zip from GitHub</p> <ol> <li>Navigate to the repository in your web browser: https://github.com/Infosys-Generative-AI/Infyagentframework</li> <li>Click the green \"Code\" button</li> <li>Select \"Download Zip\"</li> <li>Extract the Zip file to your preferred location on your machine</li> </ol> <p>Note</p> <p>ZIP file will be difficult have track of development from other developers, so avoid this option unless necessary</p>"},{"location":"Installation/windows/#branching-mechanism","title":"Branching Mechanism","text":"<p>The project uses a two-branch workflow to manage code stability and development:</p> <ul> <li> <p>main:  </p> <ul> <li>Contains stable, production-ready code.</li> <li>Deployments to the production (Linux) server are made from this branch.</li> <li>QA testing and client demos are conducted using code from <code>main</code>.</li> </ul> </li> <li> <p>development:  </p> <ul> <li>Used for ongoing development and testing.</li> <li>All new features and defect fixes are first implemented here.</li> <li>Developers create separate feature or fix branches from <code>development</code> for their work.</li> <li>After completing their task and unit testing, developers merge their feature/fix branch back into <code>development</code> to keep it up to date.</li> </ul> </li> </ul> <p>Release Process: - Once QA verifies that the application is working as expected in the <code>development</code> branch, the code is merged into <code>main</code>. - The updated <code>main</code> branch is then deployed to production for demos and further testing.</p> <p>This workflow ensures that only tested and approved code reaches production, while active development happens separately.</p>"},{"location":"Installation/windows/#download-the-frontend-project-code","title":"Download the Frontend Project Code","text":"<p>You can obtain the project files using one of the following methods:</p> <p>Option 1: Clone Using Git</p> <p>If you have Git installed, open Terminal and run:</p> <pre><code>git clone https://github.com/Infosys-Generative-AI/Agentic-Pro-UI.git\ncd Agentic-Pro-UI\n</code></pre> <ul> <li>The git clone command will create a new folder named \"Agentic-Pro-UI\" in your current directory and download all repository files into it.</li> <li>The cd command navigates into the newly created folder.</li> </ul> <p>Option 2: Download Zip from GitHub</p> <ol> <li>Navigate to the repository in your web browser: https://github.com/Infosys-Generative-AI/Agentic-Pro-UI.git</li> <li>Click the green \"Code\" button</li> <li>Select \"Download Zip\"</li> <li>Extract the Zip file to your preferred location on your machine</li> </ol>"},{"location":"Installation/windows/#setup-and-installation","title":"Setup and Installation","text":"<p>Open in Code Editor</p> <ol> <li>Open Visual Studio Code or your preferred code editor</li> <li>Select File &gt; Open Folder</li> <li>Navigate to and select the project directory</li> </ol>"},{"location":"Installation/windows/#setting-up-the-backend-environment","title":"Setting Up the Backend Environment","text":"<p>Follow these steps in Terminal (opened in the project directory):</p> <p>1. Create a Virtual Environment for the Backend:</p> <pre><code>cd backend\npython -m venv .venv\n</code></pre> <p>This creates a virtual environment named <code>.venv</code> in the backend directory.</p> <p>2. Activate the Virtual Environment:</p> <pre><code>.\\.venv\\Scripts\\activate\n</code></pre> <p>When activated successfully, you'll see <code>(.venv)</code> at the beginning of your command prompt.</p> <p>3. Install Backend Dependencies:</p> <p>With the virtual environment activated:</p> <pre><code>pip install uv\nuv pip install -r requirements.txt\n</code></pre> <p>This will install all the necessary Python packages listed in the <code>requirements.txt</code> file.</p> <p>If you face any SSL error issue, use the below command:</p> <pre><code>pip install -r requirements.txt --trusted-host pypi.org --trusted-host files.pythonhosted.org\n</code></pre>"},{"location":"Installation/windows/#setting-up-the-frontend-environment","title":"Setting Up the Frontend Environment","text":"<p>In a new Terminal window, navigate to the project's frontend directory:</p> <pre><code>cd frontend\n</code></pre> <p>Install Frontend Dependencies</p> <ul> <li>Open a terminal in the <code>frontend</code> directory.</li> <li>Run the following command to install all required packages:</li> </ul> <pre><code>npm install\n</code></pre> <ul> <li>You can also use the shorthand</li> </ul> <pre><code>npm i\n</code></pre> <ul> <li>This will start installing all the dependencies.</li> <li>Wait for the installation to complete. This may take a few minutes.</li> </ul> <p>Note</p> <ul> <li>If you see only a blinking cursor or a loader for more than 3 minutes and no progress, check your Zscaler or JFrog access settings. This usually indicates a network or authentication issue.</li> </ul>"},{"location":"Installation/windows/#configuration-setup","title":"Configuration Setup","text":"<p>Frontend Configuration</p> <p>Open <code>src/constants.js</code> and update it according to your VM configuration:</p> <pre><code>export const BASE_URL = \"http://10.779.18.602:8000\"; // Windows\n</code></pre> <ul> <li>10.779.18.602 is the IP address of the VM.</li> <li>8000 is the port where the FastAPI backend is running.</li> </ul> <p>Backend Configuration (CORS)</p> <p>Make sure your backend allows requests from the frontend. You will find these lines in <code>agentic_workflow_as_service_endpoints.py</code>:</p> <pre><code>origins = [\n    \"http://localhost\",              # Allow localhost\n    \"http://localhost:3000\",        # Frontend running on port 3000\n    \"http://10.779.18.602\",           # Local network IP\n    \"http://10.779.18.602:3000\",      # Local network IP with port\n    \"null\",                         # For file:// or sandboxed environments\n    # Add other origins as needed, such as your deployed frontend URL\n]\n</code></pre> <ul> <li>Instead of 10.779.18.602 you can have your own VM IP address.</li> <li>Instead of 3000 mention the port number where the frontend is running.</li> </ul> <p>Make sure to update the .env file with your API keys.</p>"},{"location":"Installation/windows/#running-the-project","title":"Running the Project","text":"<p>1. Start the Backend Server</p> <p>Set the environment variables to enable telemetry:</p> <pre><code>set HTTP_PROXY=\nset NO_PROXY=localhost,127.0.0.1\n</code></pre> <p>In the Terminal with the active virtual environment:</p> <pre><code>cd backend  # If not already in the backend directory\nuvicorn agentic_workflow_as_service_endpoints:app --host 0.0.0.0 --port 8000 --workers 4\n</code></pre> <p>Backend Server Details</p> <ul> <li>Server: Uvicorn (ASGI server)</li> <li>Module: <code>agentic_workflow_as_service_endpoints:app</code></li> <li>Host: 0.0.0.0 (accessible from any network interface)</li> <li>Port: 8000</li> <li>Workers: 4 processes to handle requests</li> </ul> <p>Once running, you can access the backend API at http://localhost:8000</p> <p>2. Start the React Frontend</p> <p>In a new Terminal window:</p> <pre><code>cd frontend  # If not already in the frontend directory\nnpm start\n</code></pre> <p>Frontend Server Details</p> <ul> <li>Development Server: The React development server is used for local development and testing.<ul> <li>Default Port: Runs on port <code>3000</code> by default.</li> <li>Hot Reloading: Automatically reloads the page when you make changes to the source code.</li> <li>Custom Port: To run the frontend on a different port (e.g., <code>3003</code>), open PowerShell and run:   <code>$env:PORT=3003; npm start</code></li> <li>This command starts the React development server on port <code>3003</code> instead of the default <code>3000</code>.</li> </ul> </li> </ul> <p>The React development server will start and automatically open http://localhost:3000 in your default web browser.</p>"},{"location":"Installation/windows/#how-to-make-the-server-run-247-on-windows-using-nssm","title":"How to Make the Server Run 24/7 on Windows Using NSSM","text":"<p>Step 1: Create a Batch File</p> <p>Create a new file named <code>servers.bat</code> (you can choose any name).</p> <p>Paste the following content into the file:</p> <pre><code>@echo off\nREM Activate Python virtual environment\ncd /d \"C:\\Code\\Infyagentframework-main\\Infyagentframework-main\\.venv\\Scripts\"\ncall activate.bat\n\nREM Change to project directory\ncd /d \"C:\\Code\\Infyagentframework-main\\Infyagentframework-main\\backend\"\n\nREM Start FastAPI backend\nstart cmd /k \"uvicorn agentic_workflow_as_service_endpoints:app --host 0.0.0.0 --port 8000 --workers 4\"\n\nREM Start Node.js frontend\ncd /d \"C:\\Code\\Agentic-Pro-UI\\frontend\"\nstart cmd /k \"npm start\"\n\npause\n</code></pre> <p>Important</p> <p>Make sure the file paths match your system's folder structure.</p> <p>Tip</p> <p>Save the file somewhere accessible, like your desktop or project root.</p> <p>Step 2: Install and Configure NSSM </p> <ol> <li>Download NSSM if not already installed: https://nssm.cc/download</li> <li>Open Command Prompt as Administrator. </li> </ol> <p>Note</p> <p>If you have access to an Aakash VM and can connect to it using the Remote Desktop Connection application, you will be able to run NSSM commands with administrative privileges.</p> <ol> <li>Run this command to open the NSSM setup:</li> </ol> <pre><code>nssm install infy_agent.service\n</code></pre> <p>Custom Service Name</p> <p>You can replace <code>infy_agent.service</code> with any name you prefer, such as <code>my_server_service</code>, <code>webstack_service</code>, or <code>custom_backend</code>. Just make sure to use the same name consistently in all subsequent commands.</p> <ol> <li>In the NSSM GUI:</li> <li>For Application path, browse and select your <code>servers.bat</code> file.</li> <li>Click Install Service.</li> </ol> <p>Step 3: Manage the Service</p> <p>Use these commands from the terminal (as Administrator):</p> <p>Start the service:</p> <pre><code>nssm start infy_agent.service\n</code></pre> <p>Stop the service:</p> <pre><code>nssm stop infy_agent.service\n</code></pre> <p>Edit the service:</p> <pre><code>nssm edit infy_agent.service\n</code></pre> <p>You can also go to Windows Services (press <code>Win + R</code>, type <code>services.msc</code>) to start, stop, or set the service to run automatically on startup.</p>"},{"location":"Installation/windows/#project-structure","title":"Project Structure","text":"<p>The structure shown below is a sample. The full project includes additional files and directories not listed here.</p> <pre><code>Infyagentframework/\n\u251c\u2500\u2500 backend/                  # Backend FastAPI application\n\u2502   \u251c\u2500\u2500 .venv/                # Python virtual environment (generated)\n\u2502   \u251c\u2500\u2500 requirements.txt      # Python dependencies\n\u2502   \u2514\u2500\u2500 agentic_workflow_as_service_endpoints.py  # Main API file\n\u251c\u2500\u2500 frontend/                 # React frontend application\n\u2502   \u251c\u2500\u2500 node_modules/         # Node.js dependencies (generated)\n\u2502   \u251c\u2500\u2500 public/               # Static assets\n\u2502   \u251c\u2500\u2500 src/                  # React source code\n\u2502   \u2502   \u251c\u2500\u2500 components/       # React components\n\u2502   \u2502   \u251c\u2500\u2500 pages/            # Page components\n\u2502   \u2502   \u251c\u2500\u2500 services/         # API service functions\n\u2502   \u2502   \u251c\u2500\u2500 constants.js      # Configuration constants (BASE_URL)\n\u2502   \u2502   \u251c\u2500\u2500 App.js            # Main App component\n\u2502   \u2502   \u2514\u2500\u2500 index.js          # Entry point\n\u2502   \u251c\u2500\u2500 package.json          # Node.js dependencies and scripts\n\u2502   \u2514\u2500\u2500 package-lock.json     # Lock file for dependencies\n\u2514\u2500\u2500 README.md                 # Project documentation\n</code></pre> <ul> <li><code>src/components/</code>: Contains reusable React components.</li> <li><code>src/constants.js</code>: Stores configuration constants.</li> <li><code>src/App.js</code>: Main application component.</li> <li><code>public/</code>: Static assets and the HTML template.</li> </ul>"},{"location":"Installation/windows/#troubleshooting","title":"Troubleshooting","text":"<p>Connection Issues Between Frontend and Backend</p> <p>If your React UI cannot connect to the backend:</p> <p>1. Verify BASE_URL Configuration: </p> <ul> <li>Check that <code>src/constants.js</code> has the correct backend URL</li> <li>Ensure the IP address and port match your backend server</li> </ul> <p>2. Check Backend CORS Settings: </p> <ul> <li>Confirm your frontend URL is included in the origins list</li> <li>Restart the backend server after making CORS changes</li> </ul> <p>3. Network Connectivity: </p> <ul> <li>Test if you can access the backend URL directly in your browser</li> <li>Verify both services are running on the expected ports</li> </ul> <p>4. Browser Console Errors:</p> <ul> <li>Open browser developer tools and check for CORS or network errors</li> <li>Look for specific error messages that can guide troubleshooting</li> </ul> <p>Common Issues</p> <ul> <li>Port Already in Use: If you get a port error, either stop the conflicting service or use a different port</li> <li>CORS Errors: Ensure the frontend URL is properly added to the backend's origins list</li> <li>Module Not Found: Verify all dependencies are installed and virtual environments are activated</li> </ul>"},{"location":"Telemetry/Arize_Phoenix/","title":"Arize Phoenix Setup Guide","text":""},{"location":"Telemetry/Arize_Phoenix/#python-dependencies","title":"Python Dependencies","text":"<p>Install the required packages:</p> <pre><code>pip install arize-phoenix openinference-instrumentation-langchain\n</code></pre> <ul> <li>arize-phoenix: Core Phoenix library for observability and tracing</li> <li>openinference-instrumentation-langchain: Automatic instrumentation for LangChain applications</li> </ul>"},{"location":"Telemetry/Arize_Phoenix/#trace-recording-methods","title":"Trace Recording Methods","text":"<p>Phoenix offers two primary approaches for recording traces in your application:</p> <p>Method 1: Direct Import</p> <pre><code>from phoenix.otel import register\n</code></pre> <p>Method 2: Project Context Manager</p> <pre><code>from phoenix.trace import using_project\n</code></pre>"},{"location":"Telemetry/Arize_Phoenix/#environment-variables","title":"Environment Variables","text":"<p>Configure the following environment variables for proper setup:</p> <p>Set GRPC Port</p> <ul> <li>In command prompt</li> </ul> <pre><code>set PHOENIX_GRPC_PORT=50051\n</code></pre> <ul> <li>In terminal </li> </ul> <pre><code>$env: PHOENIX_GRPC_PORT=50051\n</code></pre> <p>Default port is used by OpenTelemetry (OTEL) for trace collection and should change Phoenix's default configuration.</p>"},{"location":"Telemetry/Arize_Phoenix/#trace-storage-configuration","title":"Trace Storage Configuration","text":"<p>Phoenix provides flexible storage options for your traces:</p> <p>Default Storage (SQLite) By default, Phoenix stores traces in a local SQLite database, which is suitable for development and small-scale deployments.</p> <p>PostgreSQL Storage (Production) For production environments or when you need more robust storage, configure PostgreSQL:</p> <pre><code>set PHOENIX_SQL_DATABASE_URL=postgresql://postgres:postgres@localhost:5432/arize_traces\n</code></pre> <p>Replace the connection parameters with your actual PostgreSQL credentials:</p> <ul> <li>provide your username: <code>postgres</code></li> <li>provide your password: <code>postgres</code></li> <li>host and port: <code>localhost:5432</code></li> <li>database name: <code>arize_traces</code></li> </ul>"},{"location":"Telemetry/Arize_Phoenix/#project-registration-in-python-code","title":"Project Registration in Python Code","text":"<p>Example 1: Evaluation Service</p> <pre><code>@app.post('/evaluate')\nasync def evaluate(evaluating_model1, evaluating_model2):\n    register(\n        project_name='add-tool',\n        auto_instrument=True,\n        set_global_tracer_provider=False,\n        batch=True\n    )\n\n    with using_project('evaluation-metrics'):\n        return await process_unprocessed_evaluations(\n            model1=evaluating_model1,\n            model2=evaluating_model2\n        )\n</code></pre> <p>Configuration Parameters Explained:</p> <ul> <li><code>project_name</code>: Unique identifier for your project in Phoenix</li> <li><code>auto_instrument</code>: Automatically instruments supported libraries</li> <li><code>set_global_tracer_provider</code>: Prevents conflicts with other tracing systems</li> <li><code>batch</code>: Enables batch processing of traces for better performance</li> </ul> <p>Example 2: Tool Update Service</p> <pre><code>register(\n    project_name='update-tool',\n    auto_instrument=True,\n    set_global_tracer_provider=False,\n    batch=True\n)\n\nwith using_project('update-tool'):\n    response = await update_tool_by_id(\n        model_name=request.model_name,\n        user_email_id=request.user_email_id,\n        is_admin=request.is_admin,\n        tool_id_to_modify=tool_id,\n        tool_description=request.tool_description,\n        code_snippet=request.code_snippet,\n        updated_tag_id_list=request.updated_tag_id_list\n    )\n</code></pre>"},{"location":"Telemetry/Arize_Phoenix/#server-management","title":"Server Management","text":"<p>Starting the Phoenix Server</p> <p>Launch the Phoenix server using the following command:</p> <pre><code>python -m phoenix.server.main serve\n</code></pre> <p>Server Details for local:</p> <ul> <li>Default Port: 6006</li> <li>Endpoint: <code>http://localhost:6006</code></li> <li>Purpose: Provides web interface for trace visualization and analysis</li> </ul> <p>Server Details for VM:</p> <p>when we have network proxy on VM, before starting the backend uvicorn server set the following commands:</p> <pre><code>set HTTP_PROXY=\nset NO_PROXY=localhost,127.0.0.1\n</code></pre>"},{"location":"Telemetry/Arize_Phoenix/#user-interface-features","title":"User Interface Features","text":"<p>Phoenix Web UI Capabilities</p> <p>Once the server is running, access the web interface at <code>http://localhost:6006</code> in local.</p> <p>Project Management</p> <ul> <li>View all registered projects in a centralized dashboard</li> <li>Monitor different services and applications separately     </li> </ul> <p>Agent Monitoring</p> <ul> <li>Track individual agent performances and behaviors</li> <li> <p>Compare different models or configurations     </p> </li> <li> <p>Detailed Trace Inspection: Examine complete request flows</p> </li> <li>Token Usage Tracking: Monitor token consumption and costs </li> <li> <p>Input/Output Analysis: Review all inputs and outputs for debugging.</p> <p>sample input:   sample output: </p> </li> <li> <p>Performance Metrics: Analyze latency, throughput, and error rates</p> </li> </ul>"},{"location":"Telemetry/Connecting%20to%20Grafana/","title":"Connecting to Grafana and Creating Visualizations from Elasticsearch","text":"<p>This guide will walk you through the process of connecting Grafana to your Elasticsearch data source, configuring it, and creating visualizations and dashboards. Each step is broken down to help you set up the integration seamlessly.</p>"},{"location":"Telemetry/Connecting%20to%20Grafana/#1-provide-elasticsearch-endpoint-url-for-connection","title":"1. Provide Elasticsearch Endpoint URL for Connection","text":"<p> To begin, you must specify the Elasticsearch Endpoint URL. This URL is where Grafana will look for your Elasticsearch instance. Grafana needs this URL to establish a connection and retrieve data from Elasticsearch.</p> <p>Steps:</p> <ul> <li>Open Grafana and navigate to the Data Sources section.</li> <li>Select Add Data Source, then choose Elasticsearch from the list of available sources.</li> <li>In the HTTP URL field, enter the endpoint URL of your Elasticsearch instance.</li> <li>Click Save &amp; Test to verify the connection.</li> </ul> <p>Once the connection is successful, Grafana will confirm that the endpoint is accessible and can pull data from your Elasticsearch server.</p>"},{"location":"Telemetry/Connecting%20to%20Grafana/#2-provide-elasticsearch-details","title":"2. Provide Elasticsearch Details","text":"<p> After establishing the connection, you need to configure the details specific to your Elasticsearch data. These include the Index Name, Message Field Name, and Level Field Name.</p> <ul> <li> <p>Index Name: The index name should exactly match the one defined in your Elasticsearch configuration. It tells Grafana which index to pull data from within your Elasticsearch cluster. If you have multiple indices or time-based indices (e.g., <code>agentic-foundry-tool-log</code>), specify the exact name or pattern here.</p> </li> <li> <p>Message Field Name: This refers to the field in the Elasticsearch index that contains the actual log message or data content that you want to visualize in Grafana. For example, this might be <code>message</code> or <code>log</code> depending on your Elasticsearch mappings.</p> </li> <li> <p>Level Field Name: The level field represents the severity level of logs or events, such as <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>, or any custom field you use for classification. Ensure the field you provide matches the one used in your Elasticsearch index for filtering and aggregation.</p> </li> </ul> <p>Steps:</p> <ul> <li>In Grafana's Data Source configuration page, you\u2019ll see fields for Index Name, Message Field, and Level Field.</li> <li>Fill in the respective names that match your Elasticsearch configuration.</li> <li>After entering the information, click Save &amp; Test again to ensure everything is set up correctly.</li> </ul> <p>Once saved, Grafana will store these details and use them to pull the correct data during visualizations and dashboard creation.</p>"},{"location":"Telemetry/Connecting%20to%20Grafana/#3-adding-visualizations","title":"3. Adding Visualizations","text":"<p> With the connection established and data source configured, you are now ready to add visualizations to your Grafana dashboard. Visualizations are charts, graphs, or tables that will display your data in meaningful ways.</p> <p></p> <p>Steps:</p> <ul> <li>From the Grafana homepage, click on the Plus (+) symbol located on the left-hand sidebar.</li> <li>Select Dashboard from the options that appear.</li> <li>A new, empty dashboard will open. Click on Add new panel.</li> <li>In the panel configuration page, select the Data Source you created in Step 2.</li> <li>Choose a visualization type (e.g., Graph, Time series, Table, etc.).</li> <li>Grafana will automatically query Elasticsearch using the configured Index Name and fields and display the results in the chosen visualization format.</li> </ul> <p>Once you\u2019ve configured your panel, click Save to add it to your dashboard. You can repeat this process to add multiple visualizations to your dashboard, each representing different aspects of your data.</p> <p>After adding a data source, the dashboard will be updated to display the newly integrated data. From here, you can create a wide range of visualizations based on the available data.</p> <p></p> <p>Additional Configurations:</p> <ul> <li>Filters: Grafana allows you to use Filters to narrow down the data displayed. For example, you can filter logs by date, severity level, or specific keywords.</li> <li>Variables: You can define Variables (e.g., <code>session_id</code>, <code>action_id</code>, or <code>action_on</code>) that can be used as dynamic filters across multiple panels. This allows for interactive and flexible dashboards where users can change the value of a variable and see the dashboard update accordingly.</li> </ul>"},{"location":"Telemetry/Connecting%20to%20Grafana/#4-filters-and-variables","title":"4. Filters and Variables","text":"<p>To make your dashboards more dynamic, Grafana supports the use of Filters and Variables. These allow you to control what data is displayed in real-time, making it easy to customize and adjust visualizations on the fly.</p> <p></p> <p>Filters: Filters are conditions that can be applied to specific fields in the Elasticsearch index. They are especially useful for narrowing down data, such as:</p> <ul> <li>Displaying only logs from a particular time range.</li> <li>Filtering logs based on severity level (e.g., showing only <code>ERROR</code> logs).</li> <li>Displaying data related to specific services or hosts.</li> </ul> <p>Variables: Variables in Grafana let you create dynamic dashboards that can adapt based on user input. Once a variable is defined, it can be used in the queries that power your visualizations. This makes it easy for users to filter data on the fly without modifying the queries directly.</p> <p>Steps:</p> <ul> <li>Navigate to Dashboard Settings (the gear icon on the top-right corner of your dashboard).</li> <li>Select Variables from the menu.</li> <li>Create a new variable (e.g., <code>Host</code>, <code>Service</code>, <code>Log Level</code>) and define its options (e.g., available hosts or log levels).</li> <li>Use this variable in your queries to make your dashboards more interactive.</li> </ul> <p>For example, you could create a variable <code>Host</code> that lets users select the host from a dropdown, and the graphs on the dashboard will automatically update to show data for that selected host.</p>"},{"location":"Telemetry/Connecting%20to%20Grafana/#5-sample-final-dashboard","title":"5. Sample Final Dashboard","text":"<p>Once all the visualizations are configured, your Grafana dashboard should look something like the following example, where you can interact with various filters, variables, and different types of graphs.</p> <p>Final Output: </p> <p>By using the Filters and Variables, users can interactively explore the data, focusing on different aspects like time periods, severity levels, and specific hosts or services.</p> <p>Dashboard Severity Filter Options</p> <p>In the final dashboard, we have additional filtering capabilities under the Severity section. Instead of selecting all severity levels at once, users can filter and view the dashboard data separately based on the following four options:</p> <ul> <li>Error</li> <li>Debug</li> <li>Info</li> <li>Warn</li> </ul> <p></p>"},{"location":"Telemetry/configurations/","title":"Configurations","text":""},{"location":"Telemetry/configurations/#configurations-for-connecting-with-opentelemetry-collector-and-elastic-search","title":"configurations for connecting with  opentelemetry collector and elastic search.","text":"<pre><code># ======================== Elasticsearch Configuration =========================\n# ... (all the commented out default settings can remain commented) ...\n\n# ---------------------------------- Cluster -----------------------------------\ncluster.name: my-local-dev-cluster # Give it a simple name\n\n# ------------------------------------ Node ------------------------------------\nnode.name: node-1 # Simple node name\n\n# ----------------------------------- Paths ------------------------------------\n# It's good practice to define these, even if using defaults,\n# especially if you run multiple ES instances later.\n# Default paths are usually within the ES installation directory.\n# path.data: data\n# path.logs: logs\n\n# ---------------------------------- Network -----------------------------------\n# Bind to localhost only for local development for better security\nnetwork.host: 127.0.0.1\nhttp.port: 9200\n\n# --------------------------------- Discovery ----------------------------------\n# Critical for a single-node development setup\ndiscovery.type: single-node\n\n# --- VITAL: Disable Security for Local Development ---\n# --- Delete or comment out the entire auto-generated security block ---\n# --- and add these lines instead: ---\n\nxpack.security.enabled: false\nxpack.security.enrollment.enabled: false # Not relevant if security is off\nxpack.security.http.ssl.enabled: false   # Disable SSL for HTTP\nxpack.security.transport.ssl.enabled: false # Disable SSL for inter-node communication\n\n# --- END VITAL SECURITY MODIFICATION ---\n\n# You can leave the rest of the file as is (mostly commented out defaults).\n# The auto-generated cluster.initial_master_nodes is not needed if discovery.type=single-node\n# and security is off.\n# The http.host: 0.0.0.0 can be changed to 127.0.0.1 for better local security.\n</code></pre> <p><code>config.yaml</code> file</p> <pre><code>\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4319 # Your existing gRPC endpoint\n      http:\n        endpoint: 0.0.0.0:4320 # Your existing HTTP endpoint\n\nexporters:\n  debug:\n    verbosity: detailed\n  elasticsearch:\n    endpoints: [\"http://localhost:9200\"]\n    logs_index: \"agentic-foundry-tool-logs\"\n    sending_queue:\n      enabled: true # Just enable the queue, rely on its defaults for retry\n\nprocessors:\n  batch:\n    # send_batch_size: 8192\n    # timeout: 1s\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug] # Add 'elasticsearch' if you also want to send traces to ES\n\n    metrics:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug] # Add 'elasticsearch' if you also want to send metrics to ES\n\n    logs:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, elasticsearch] # Send logs to both debug and Elasticsearch\n\n  telemetry:\n    logs:\n      level: info\n    metrics:\n      level: basic\n      address: localhost:8889\n\n</code></pre>"},{"location":"Telemetry/configurations/#starting-the-opentelemetry-collector","title":"Starting the OpenTelemetry Collector","text":"<p>To start the OpenTelemetry Collector, follow these steps:</p> <p>1. Navigate to the OpenTelemetry Collector directory:</p> <pre><code>cd &lt;path_to_otel_collector_directory&gt;\n</code></pre> <p>2. Run the Collector with your configuration file:</p> <pre><code>&lt;otel_collector_executable&gt; --config \"&lt;path_to_config_file&gt;\"\n#example\notelcol-contrib.exe --config \"C:\\Users\\user\\Downloads\\config.yaml\"\n</code></pre>"},{"location":"Telemetry/configurations/#starting-elasticsearch-and-loading-modules","title":"Starting Elasticsearch and Loading Modules","text":"<p>1. Navigate to the bin Folder:</p> <p>Open your command prompt or terminal and go to the Elasticsearch installation directory. Then, proceed to the bin folder.</p> <p>2. Run the Batch File:</p> <p>Inside the bin folder, execute the appropriate batch file. This will start Elasticsearch and automatically load all necessary modules.</p>"},{"location":"Telemetry/telemetry/","title":"Telemetry","text":""},{"location":"Telemetry/telemetry/#key-components-of-telemetry","title":"Key Components of Telemetry:","text":"<ol> <li>Logs: Captures LLM inputs, outputs, prompts, responses, errors, and debugging information.</li> <li>Traces: Tracks the chain of thought, agent decisions, and agent state to observe how individual LLM tasks are executed.</li> </ol>"},{"location":"Telemetry/telemetry/#opentelemetry-workflow","title":"OpenTelemetry Workflow","text":"<p>OpenTelemetry is an open-source framework for collecting telemetry data (logs and traces) from applications. Below is an explanation of the workflow:</p> <ol> <li>OpenTelemetry - Logging Statements (Actions): Logs are generated in the application code using OpenTelemetry libraries.</li> <li>OpenTelemetry Collector - Transfers Logs from Code: The OpenTelemetry Collector gathers logs from the application and forwards them to a suitable backend.</li> <li>ElasticSearch - Log Format Compatibility: Logs are stored in ElasticSearch, which provides a structured and searchable format for telemetry data.</li> <li>ElasticSearch - Grafana Connection: ElasticSearch integrates with Grafana to visualize the telemetry data.</li> <li>Final Dashboard: Grafana displays the logs and metrics in a user-friendly dashboard for monitoring and analysis.</li> </ol>"},{"location":"Telemetry/telemetry/#telemetry-flowchart","title":"Telemetry Flowchart","text":"OpenTelemetryLogging Statements \u2193 Open telemetry collectorTransfer Logs \u2193 ElasticsearchFor Longer Format \u2193 GraphanaConnection to Graphana \u2193 Final Dashboard"},{"location":"Telemetry/telemetry/#data-collection-monitoring","title":"Data Collection &amp; Monitoring","text":"<ul> <li> <p>Data Collection:  The OpenTelemetry SDK is used to collect traces and logs from the agent framework, capturing detailed telemetry data.</p> </li> <li> <p>Data Export: The OpenTelemetry Collector transfers the collected logs and traces from the framework to an external storage or analysis system.</p> </li> <li> <p>Centralized Storage &amp; Anlysis: All telemetry data is centrally stored in ElasticSearch, enabling structured storage and efficient querying.</p> </li> <li> <p>Visualization: Grafana retrieves data from the centralized storage to populate dashboards, offering real-time insights into application performance, user interactions, and agent workflows.</p> </li> </ul>"},{"location":"Telemetry/telemetry/#implementation-of-opentelemetry-logging","title":"Implementation of OpenTelemetry Logging","text":"<p>The <code>setup_otel_logging</code> function initializes the OpenTelemetry logging pipeline for an application. It ensures that logs are collected, processed, and exported to a backend system for analysis. </p> <pre><code>import logging, atexit \nfrom opentelemetry import trace, _logs \nfrom logging import Logger\nfrom functools import wraps\nfrom opentelemetry.sdk._logs.export import BatchLogRecordProcessor \nfrom opentelemetry.exporter.otlp.proto.http._log_exporter import OTLPLogExporter as OTLPLogExporterHTTP \nfrom opentelemetry.sdk._logs import (\n    LoggerProvider,\n    LoggingHandler \n)\nfrom opentelemetry.sdk.resources import (\n    Resource,\n    SERVICE_NAME  \n)\n\n\n# --- Global variable to hold the configured provider (initialized once) ---\n_otel_logger_provider = None\nUSE_OTEL_LOGGING = False # keep it as True in VM for Otel Collector, False in local dev\n\n# --- Function for one-time OTel logging setup ---\ndef setup_otel_logging(service_name=\"agentic-workflow-service\", use_http=True):\n    \"\"\"\n    Initializes the OpenTelemetry logging pipeline. Should be called once.\n    \"\"\"\n    global _otel_logger_provider\n    if _otel_logger_provider is not None:\n        print(\"--- OpenTelemetry Logging already initialized. ---\")\n        return _otel_logger_provider\n\n    print(f\"--- Setting up OpenTelemetry Logging for service: {service_name} ---\")\n    resource = Resource(attributes={SERVICE_NAME: service_name})\n\n    if use_http:\n        default_endpoint = \"http://localhost:4320/v1/logs\"\n        env_var_name = \"OTEL_EXPORTER_OTLP_LOGS_ENDPOINT_HTTP\"\n        ExporterClass = OTLPLogExporterHTTP\n        protocol = \"HTTP\"\n    else: # Assuming gRPC for the else case, ensure opentelemetry-exporter-otlp-proto-grpc is installed\n        default_endpoint = \"localhost:4319\"\n        env_var_name = \"OTEL_EXPORTER_OTLP_LOGS_ENDPOINT_GRPC\"\n        try:\n            from opentelemetry.exporter.otlp.proto.grpc._log_exporter import OTLPLogExporter as OTLPLogExporterGRPC\n            ExporterClass = OTLPLogExporterGRPC\n        except ImportError:\n            print(\"[ERROR] OTLP gRPC Exporter not found. Please install 'opentelemetry-exporter-otlp-proto-grpc'. Falling back to HTTP.\")\n            default_endpoint = \"http://localhost:4320/v1/logs\" # Fallback\n            env_var_name = \"OTEL_EXPORTER_OTLP_LOGS_ENDPOINT_HTTP\"\n            ExporterClass = OTLPLogExporterHTTP\n            protocol = \"HTTP\"\n        protocol = \"gRPC\"\n\n\n    otlp_endpoint = os.getenv(env_var_name, default_endpoint)\n    print(f\"--- OTLP Log Exporter ({protocol}) Endpoint: {otlp_endpoint} ---\")\n    exporter_args = {\"endpoint\": otlp_endpoint}\n\n    # Add headers if needed\n    headers_str = os.getenv(\"OTEL_EXPORTER_OTLP_LOGS_HEADERS\")\n    if headers_str:\n        try:\n            exporter_args[\"headers\"] = dict(item.split(\"=\") for item in headers_str.split(\",\"))\n            print(f\"--- Using OTLP Headers: {exporter_args['headers']} ---\")\n        except ValueError:\n            print(f\"[ERROR] Invalid format for OTEL_EXPORTER_OTLP_LOGS_HEADERS. Expected 'key1=value1,key2=value2'.\")\n\n\n    try:\n      log_exporter = ExporterClass(**exporter_args)\n    except Exception as e:\n        print(f\"[ERROR] Failed to initialize OTLP exporter ({protocol}): {e}\")\n        return None\n\n    _otel_logger_provider = LoggerProvider(resource=resource)\n    _logs.set_logger_provider(_otel_logger_provider)\n    log_processor = BatchLogRecordProcessor(log_exporter)\n    _otel_logger_provider.add_log_record_processor(log_processor)\n\n    print(\"--- OpenTelemetry Logging Setup Complete ---\")\n    return _otel_logger_provider\n\n</code></pre> <p><code>USE_OTEL_LOGGING</code> Configuration Flag</p> <p>The <code>USE_OTEL_LOGGING</code> flag determines whether OpenTelemetry (Otel) logging is enabled in your application, and it helps control the telemetry data flow between your application and the OpenTelemetry Collector. This flag is particularly useful in managing the difference between development and production environments.</p> <p>Local Development:</p> <pre><code>USE_OTEL_LOGGING = False  # Default value for local development\n</code></pre> <p>When developing locally, If the required dependencies are not available or if logging is disabled by setting USE_OTEL_LOGGING to false, the system will output relevant information to the console when you run the file. This ensures you are informed of any missing configurations or services, helping to avoid confusion during local development.</p> <p>Production or Remote Environments:</p> <pre><code>USE_OTEL_LOGGING = True  # Set this to True when running in a VM or production environment\n</code></pre> <p>In production or more complex environments (e.g., Virtual Machines), telemetry data collection (such as logs, traces, and metrics) is crucial for monitoring and troubleshooting application performance. This flag ensures the application sends telemetry data to the Otel Collector in such environments.</p>"},{"location":"Telemetry/telemetry/#components","title":"Components","text":"<p>1. SessionContext class </p> <p>The <code>SessionContext</code> class manages session specific metadata. It allows setting and retrieving context values.</p> <pre><code>class SessionContext:\n    _context = {}\n\n    @classmethod\n    def _serialize_if_complex(cls, value):\n        \"\"\"Helper to serialize lists/dicts to JSON strings, pass others.\"\"\"\n        if isinstance(value, (list, dict)):\n            try:\n                return json.dumps(value)\n            except TypeError as e:\n                # Fallback for unserializable objects: convert to string\n                # You might want more sophisticated handling or logging here\n                print(f\"[WARNING] SessionContext: Could not JSON serialize value of type {type(value)}, falling back to str(): {e}\")\n                return str(value)\n        return value\n\n    @classmethod\n    def set(\n        cls,\n        user_id=None, session_id=None, agent_id=None,\n        tool_id=None, tool_name=None, model_used=None,\n        tags=None, agent_name=None, agent_type=None, tools_binded=None,\n        agents_binded=None, user_query=None, response=None,\n        action_type=None, action_on=None, previous_value=None, new_value=None\n    ):\n        \"\"\"Update specific fields, JSON serializing complex types.\"\"\"\n        if user_id is not None: cls._context['user_id'] = user_id\n        if session_id is not None: cls._context['session_id'] = session_id\n        if agent_id is not None: cls._context['agent_id'] = agent_id\n        if agent_name is not None: cls._context['agent_name'] = agent_name\n        if tool_id is not None: cls._context['tool_id'] = tool_id\n        if tool_name is not None: cls._context['tool_name'] = tool_name\n        if model_used is not None: cls._context['model_used'] = model_used\n\n        # Serialize complex fields\n        if tags is not None: cls._context['tags'] = cls._serialize_if_complex(tags)\n        if agent_type is not None: cls._context['agent_type'] = agent_type\n        if tools_binded is not None: cls._context['tools_binded'] = cls._serialize_if_complex(tools_binded)\n        if agents_binded is not None: cls._context['agents_binded'] = cls._serialize_if_complex(agents_binded)\n        if user_query is not None: cls._context['user_query'] = cls._serialize_if_complex(user_query) \n        if response is not None: cls._context['response'] = cls._serialize_if_complex(response) \n        if action_type is not None: cls._context['action_type'] = action_type\n        if action_on is not None: cls._context['action_on'] = action_on\n        if previous_value is not None: cls._context['previous_value'] = cls._serialize_if_complex(previous_value)\n        if new_value is not None: cls._context['new_value'] = cls._serialize_if_complex(new_value)\n\n\n    @classmethod\n    def get(cls):\n        \"\"\"Retrieve all context values, defaulting to 'Unassigned' if not set\"\"\"\n        return (\n            cls._context.get('user_id', 'Unassigned'),\n            cls._context.get('session_id', 'Unassigned'),\n            cls._context.get('agent_id', 'Unassigned'),\n            cls._context.get('agent_name', 'Unassigned'),\n            cls._context.get('tool_id', 'Unassigned'),\n            cls._context.get('tool_name', 'Unassigned'),\n            cls._context.get('model_used', 'Unassigned'),\n            cls._context.get('tags', 'Unassigned'),\n            cls._context.get('agent_type', 'Unassigned'),\n            cls._context.get('tools_binded', 'Unassigned'), \n            cls._context.get('agents_binded', 'Unassigned'),\n            cls._context.get('user_query', 'Unassigned'),   \n            cls._context.get('response', 'Unassigned'),     \n            cls._context.get('action_type', 'Unassigned'),\n            cls._context.get('action_on', 'Unassigned'),\n            cls._context.get('previous_value', 'Unassigned'),\n            cls._context.get('new_value', 'Unassigned')     \n        )\n</code></pre> <p>2. update_session_context function</p> <p>This <code>update_session_context</code> function dynamically updates the session context.</p> <pre><code>ef update_session_context(\n        user_id=None, session_id=None, agent_id=None,agent_name=None, tool_id=None, tool_name=None,\n        model_used=None, tags=None, agent_type=None,\n        tools_binded=None, agents_binded=None, user_query=None, response=None,\n        action_type=None, action_on=None, previous_value=None, new_value=None\n    ):\n    SessionContext.set(\n        user_id=user_id, session_id=session_id, agent_id=agent_id, agent_name=agent_name,\n        tool_id=tool_id, tool_name=tool_name, model_used=model_used, tags=tags,\n        agent_type=agent_type, tools_binded=tools_binded, agents_binded=agents_binded,\n        user_query=user_query, response=response, action_type=action_type, action_on=action_on,\n        previous_value=previous_value, new_value=new_value\n    )\n</code></pre> <p>3. CustomFilter class</p> <p>The CustomFilter class is a custom logging filter that enriches log records with additional context-specific attributes and trace/span IDs. It ensures that logs contain detailed metadata, making them more informative and traceable in distributed systems.</p> <pre><code>class CustomFilter(logging.Filter):\n    def filter(self, record):\n        (\n            user_id, session_id, agent_id, agent_name,\n            tool_id, tool_name, model_used, tags,\n            agent_type, tools_binded, agents_binded, user_query, response,\n            action_type, action_on, previous_value, new_value\n        ) = SessionContext.get()\n\n        current_span = trace.get_current_span()\n        record.trace_id = \"00000000000000000000000000000000\"\n        record.span_id = \"0000000000000000\"\n        if current_span and current_span.get_span_context().is_valid:\n            record.trace_id = \"{trace:032x}\".format(trace=current_span.get_span_context().trace_id)\n            record.span_id = \"{span:016x}\".format(span=current_span.get_span_context().span_id)\n\n        record.user_id = user_id\n        record.session_id = session_id\n        record.agent_id = agent_id\n        record.agent_name = agent_name\n        record.tool_id = tool_id\n        record.tool_name = tool_name\n        record.model_used = model_used\n        record.tags = tags \n        record.agent_type = agent_type\n        record.tools_binded = tools_binded \n        record.agents_binded= agents_binded \n        record.user_query = user_query  \n        record.response = response      \n        record.action_type = action_type\n        record.action_on = action_on\n        record.previous_value = previous_value  \n        record.new_value = new_value          \n\n        return True\n</code></pre> <p>4. get_logger function</p> <p>The <code>get_logger</code> function creates and configures a logger with context-specific attributes and integrates it with OpenTelemetry (OTel) for enhanced observability. This logger is designed to capture detailed logs enriched with trace and span information, making it suitable for distributed systems.</p> <pre><code>def get_logger(otel_provider_instance) -&gt; Logger: \n    \"\"\"Create a logger with context-specific attributes and OTel handler\"\"\"\n\n    if otel_provider_instance is None:\n        print(\"[ERROR] OpenTelemetry Logging provider is None in get_logger. Attempting fallback init.\")\n        otel_provider_instance = setup_otel_logging()\n        if otel_provider_instance is None:\n             raise RuntimeError(\"OpenTelemetry Logging not initialized and fallback failed. Cannot create OTel handler.\")\n\n    log_format = \"%(asctime)s [%(levelname)s] [%(filename)s:%(lineno)d] [trace_id=%(trace_id)s span_id=%(span_id)s] [%(name)s] [SessID:%(session_id)s AgentID:%(agent_id)s] - %(message)s\"\n    formatter = logging.Formatter(log_format, datefmt=\"%Y-%m-%d %H:%M:%S\")\n\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n    console_handler.setLevel(logging.WARNING)\n\n    otel_handler = LoggingHandler(level=logging.DEBUG, logger_provider=otel_provider_instance)\n\n    log = logging.getLogger(\"agentic_workflow_logger\") \n    log.setLevel(logging.DEBUG)\n\n    # Check if handlers of specific types are already added to prevent duplicates more robustly\n    has_console_handler = any(isinstance(h, logging.StreamHandler) for h in log.handlers)\n    has_otel_handler = any(isinstance(h, LoggingHandler) for h in log.handlers)\n    has_custom_filter = any(isinstance(f, CustomFilter) for f in log.filters)\n\n    if not has_console_handler: log.addHandler(console_handler)\n    if not has_otel_handler: log.addHandler(otel_handler)\n    if not has_custom_filter: log.addFilter(CustomFilter())\n\n    return log\n</code></pre> <p>Example Usage:</p> <ul> <li>Initialize OTel Logging</li> <li>Call setup using HTTP by default, matching the intended collector port 4320</li> </ul> <pre><code>_otel_logger_provider = None\nif USE_OTEL_LOGGING:\n    _otel_logger_provider = setup_otel_logging(\n        service_name=\"agentic-workflow-service\",\n        use_http=True\n    )\n</code></pre> <ul> <li>Initialize the logger instance that other modules will import</li> <li>Check if provider setup was successful before creating logger</li> </ul> <pre><code>if _otel_logger_provider:\n    logger = get_logger(_otel_logger_provider)\nelse:\n    print(\"[WARNING] OTel setup skipped or failed. Falling back to console-only logging.\")\n    logger = logging.getLogger(\"agentic_workflow_logger_fallback\")\n    if not logger.handlers:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n        logger.setLevel(logging.DEBUG)\n</code></pre> <p>shutdown function: </p> <pre><code>def shutdown_otel_logging():\n    global _otel_logger_provider\n    if _otel_logger_provider:\n        print(\"--- Shutting down OpenTelemetry Logging ---\")\n        try:\n            _otel_logger_provider.shutdown()\n            print(\"--- OpenTelemetry Logging Shutdown Complete ---\")\n        except Exception as e:\n            print(f\"[ERROR] Exception during OTel logging shutdown: {e}\")\n        finally:\n            _otel_logger_provider = None\n</code></pre> <ul> <li>Register the shutdown function to be called when the Python process exits</li> </ul> <pre><code>atexit.register(shutdown_otel_logging)\n</code></pre>"},{"location":"Telemetry/telemetry/#benefits-of-telemetry","title":"Benefits of Telemetry","text":"<ul> <li>Improved Monitoring: Real-time insights into system performance.</li> <li>Faster Debugging: Easier identification of issues through logs and traces.</li> <li>Enhanced Optimization: Data-driven decisions to improve system efficiency.</li> <li>Scalability: Suitable for distributed systems and microservices.</li> </ul> <p>By leveraging OpenTelemetry, ElasticSearch, and Grafana, organizations can build robust observability pipelines to monitor and maintain their systems effectively.</p>"},{"location":"agent_config/Overview/","title":"Agent Configuration","text":"<p>The Agent Configuration is a core functionality in agentic framework that enables users to create, update, and delete agents.</p>"},{"location":"agent_config/Overview/#what-is-an-agent","title":"What is an Agent?","text":"<p>An agent is composed of three core components:</p> <ol> <li> <p>Large Language Model (LLM)     The core reasoning engine that drives the agent's behavior.</p> </li> <li> <p>Tools     A set of Python functions (onboarded as tools) that the agent can call to perform actions such as querying data, generating content, or interacting with systems.</p> </li> <li> <p>Prompt (Workflow Description)     A detailed set of instructions that guides the agent's decisions and actions.</p> </li> </ol>"},{"location":"agent_config/Overview/#agent-configuration-overview","title":"Agent Configuration Overview","text":"<p>Agent configuration involves using a reusable, template-driven setup that allows creation of agents with specific roles, goals, and personas.</p>"},{"location":"agent_config/Overview/#templates-overview","title":"Templates Overview","text":"<p>The system supports three types of agent templates and each template offers different capabilities, suited for specific use cases:</p> <ol> <li> <p>React Agent: The ReAct (Reasoning and Acting) agent combines reasoning traces with action execution.</p> </li> <li> <p>Multi Agent: The multi agent follows the Plan and Execute paradigm.</p> </li> <li> <p>Meta Agent: An agent supervisor is responsible for routing to individual agents.</p> </li> </ol>"},{"location":"agent_config/metaAgent/","title":"Meta Agent Configuration","text":"<p>Meta Agent Serves as the central decision making entity. Individual agents are coordinated by a central supervisor agent. The supervisor controls all communication flow and task delegation, making decisions about which agent to invoke based on the current context and task requirements.</p>"},{"location":"agent_config/metaAgent/#meta-agent-onboarding","title":"Meta Agent Onboarding","text":"<p>The following are the steps for onboarding the Meta agent with an example:</p> <ol> <li> <p>Select Template: Select agent template.</p> <ul> <li><code>Agent Template</code>  META AGENT </li> </ul> </li> <li> <p>Select Agents: from the listed Agents - select the <code>React</code> or <code>Multi</code> Agent/s using which we want to create the meta agent.</p> <ul> <li><code>Agents</code>   Movie Recommendation Agent, Research_Scholar_Agent </li> </ul> </li> <li> <p>Agent Name:  Provide a suitable agent name. </p> <ul> <li><code>Agent Name</code>  Movie_and_scholar_Agent</li> </ul> </li> <li> <p>Agent Goal:  Provide goal of the agent - objective of the agent.</p> <ul> <li><code>Agent Goal</code> To intelligently process user queries by dynamically identifying their intent whether for entertainment or academic research and delivering personalized movie recommendations using real-time Wikipedia data or generating structured academic insights through the analysis of recent scholarly literature. The workflow is designed to provide tailored, context-aware content, enhancing both leisure exploration and research discovery through a unified, tool driven pipeline.</li> </ul> </li> <li> <p>Workflow description: Provide detailed instructions to the LLM - Guidelines to the agent. </p> <ul> <li> <p><code>Sample Workflow description</code>:</p> <p>User Input and Intent Classification:</p> <p>The user initiates the interaction by entering a query, such as:</p> <ul> <li>\u201cTop action movies about war\u201d</li> <li>\u201cExplore the intersection of AI and climate modeling\u201d</li> </ul> <p>The system classifies the query into one of two categories:</p> <ul> <li>Entertainment Query (Movie-Related)</li> <li>Academic/Research Topic</li> </ul> <p>Movie Recommendation Path:</p> <p>Step 1: Movie Query Collection Prompt the user to provide a movie-related query, e.g., \u201cTop 10 adventure movies of all time.\u201d</p> <p>Step 2: Wikipedia Search Search Wikipedia for the query and retrieve the first relevant list-type article.</p> <p>Step 3: Extract Movie Links Extract individual movie article URLs from the retrieved Wikipedia page.</p> <p>Step 4: Scrape Movie Metadata Scrape metadata (e.g., title, genre, synopsis, director, release year, ratings) from the movie URLs.</p> <p>Step 5: Generate Recommendations Use the scraped metadata to generate personalized movie recommendations with summaries and rationale.</p> <p>Academic Research Path:</p> <p>Step 1: Research Topic Collection Prompt the user to input a research topic, e.g., \u201cRecent developments in quantum cryptography.\u201d</p> <p>Step 2: Literature Search Search Semantic Scholar for recent academic papers based on the query, retrieving details like title, abstract,      &gt; authors, and DOI.</p> <p>Step 3: Publication Analysis Analyze the retrieved papers to extract structured insights, including main findings, methodologies, and research gaps.</p> <p>Step 4 (Conditional): Cross-Disciplinary Synthesis If the query spans multiple disciplines (e.g., \u201cAI\u201d + \u201cHealthcare\u201d), generate a synthesis report highlighting shared &gt; challenges, innovation opportunities, and complementary methods.</p> <p>Step 5: Academic Report Generation Compile findings into a formal academic report with sections like Title, Abstract, Literature Review, and Conclusion.</p> </li> </ul> </li> <li> <p>Model Name: Select the model name from the dropdown - which is used to create system prompt based on provided Agent goal and Workflow description.  </p> </li> </ol> <p>System Prompt: Final guidelines for the agent - created by LLM based on provided Agent goal and Workflow description for the agent.</p> <pre><code>#### Agent Name  \nMovie_and_scholar_Agent  \n\n---\n\n#### Goal to Achieve for the Workflow  \nThe **Movie_and_scholar_Agent** is designed to intelligently process user queries by dynamically identifying their intent\u2014whether for entertainment (movie-related) or academic research\u2014and delivering tailored, high-quality outputs. The Meta Agent must:  \n1. **Classify User Intent**: Accurately determine whether the query is entertainment-focused or research-oriented.  \n2. **Leverage Worker Agents**: Efficiently delegate tasks to the appropriate worker agents (Movie Recommendation Agent or Research_Scholar_Agent) based on the classified intent.  \n3. **Ensure Workflow Completion**: Oversee the end-to-end execution of the workflow, ensuring the user receives personalized movie recommendations or structured academic insights.  \n4. **Maintain Context Awareness**: Adapt responses to the user\u2019s specific query, ensuring relevance, accuracy, and clarity in the final output.  \n\n---\n\n#### Guidelines on Worker Agents Provided by the User  \n\n1. **Movie Recommendation Agent**  \n   - **Key Features**:  \n     - Provides personalized movie recommendations based on genres, themes, and ratings.  \n     - Extracts and analyzes movie metadata from Wikipedia to generate recommendations.  \n   - **Role in Workflow**:  \n     - Handles all tasks related to entertainment queries, including Wikipedia searches, metadata extraction, and recommendation generation.  \n   - **Limitations**:  \n     - Relies on Wikipedia for movie data; may not cover all movies or provide exhaustive metadata.  \n\n2. **Research_Scholar_Agent**  \n   - **Key Features**:  \n     - Conducts advanced academic searches using recent scholarly literature.  \n     - Analyzes publications to extract findings, methodologies, and research gaps.  \n     - Synthesizes insights across disciplines and generates formal academic reports.  \n   - **Role in Workflow**:  \n     - Manages all tasks related to academic research, including literature search, analysis, synthesis, and report generation.  \n   - **Limitations**:  \n     - Dependent on the availability of recent academic papers and cross-disciplinary synthesis triggers.  \n\n---\n\n#### Step-by-Step Task Execution  \n\n**Step 1: User Input Collection**  \n- **Action**: Prompt the user to input their query or topic.  \n- **Meta Agent Responsibility**:  \n  - Collect the query and ensure it is clear and well-structured.  \n  - Example Queries:  \n    - Entertainment: \u201cTop action movies about war\u201d  \n    - Academic: \u201cExplore the intersection of AI and climate modeling\u201d  \n\n---\n\n**Step 2: Intent Classification**  \n- **Action**: Analyze the user query to classify it as either an **Entertainment Query** or an **Academic/Research Topic**.  \n- **Meta Agent Responsibility**:  \n  - Use keywords, structure, and context to determine intent.  \n  - Decision Points:  \n    - If the query is movie-related \u2192 Proceed to the **Movie Recommendation Path**.  \n    - If the query is research-oriented \u2192 Proceed to the **Academic Research Path**.  \n\n---\n\n### Movie Recommendation Path (If Movie Intent Detected)  \n\n**Step 3: Movie Query Collection**  \n- **Action**: Confirm or refine the user\u2019s movie-related query for better specificity.  \n- **Meta Agent Responsibility**:  \n  - Ensure the query is actionable for the Movie Recommendation Agent.  \n  - Example: \u201cTop 10 adventure movies of all time\u201d \u2192 Refine if needed.  \n\n**Step 4: Wikipedia Search**  \n- **Action**: Trigger the `search_wikipedia_page` function.  \n- **Worker Agent Involved**: Movie Recommendation Agent.  \n- **Input**: User-provided query.  \n- **Output**: First relevant Wikipedia article URL (e.g., a list of movies).  \n\n**Step 5: Extract Movie Links**  \n- **Action**: Trigger the `extract_movie_links` function.  \n- **Worker Agent Involved**: Movie Recommendation Agent.  \n- **Input**: Wikipedia list article URL.  \n- **Output**: List of individual movie Wikipedia article URLs.  \n\n**Step 6: Scrape Movie Metadata**  \n- **Action**: Trigger the `scrape_movie_details` function.  \n- **Worker Agent Involved**: Movie Recommendation Agent.  \n- **Input**: Movie article URLs.  \n- **Output**: Metadata for each movie, including title, genre, synopsis, director, year of release, and ratings.  \n\n**Step 7: Generate Movie Recommendations**  \n- **Action**: Trigger the `get_movie_recommendations_from_wikipedia` function.  \n- **Worker Agent Involved**: Movie Recommendation Agent.  \n- **Input**: Original user query + scraped metadata.  \n- **Output**: Personalized movie recommendations with rationale and summaries.  \n\n**Step 8: Deliver Results**  \n- **Action**: Present the recommendations to the user in a clear and engaging format.  \n- **Meta Agent Responsibility**:  \n  - Ensure the output aligns with the user\u2019s preferences and query intent.  \n\n---\n\n### Academic Research Path (If Research Intent Detected)  \n\n**Step 3: Research Topic Collection**  \n- **Action**: Confirm or refine the user\u2019s research topic for clarity and specificity.  \n- **Meta Agent Responsibility**:  \n  - Ensure the topic is actionable for the Research_Scholar_Agent.  \n  - Example: \u201cRecent developments in quantum cryptography\u201d \u2192 Refine if needed.  \n\n**Step 4: Literature Search**  \n- **Action**: Trigger the `search_semantic_scholar` function.  \n- **Worker Agent Involved**: Research_Scholar_Agent.  \n- **Input**: User query or research topic (optional paper limit: default 5).  \n- **Output**: List of recent academic papers, including title, abstract, authors, publication year, source/venue, and DOI/link.  \n\n**Step 5: Publication Analysis**  \n- **Action**: Trigger the `analyze_publication` function for each retrieved paper.  \n- **Worker Agent Involved**: Research_Scholar_Agent.  \n- **Input**: Title and year of each paper.  \n- **Output**: Structured academic insights, including main findings, methodologies, applications, and research gaps.  \n\n**Step 6 (Conditional): Cross-Disciplinary Synthesis**  \n- **Action**: Trigger the `cross_disciplinary_synthesis` function if the query involves multiple disciplines.  \n- **Worker Agent Involved**: Research_Scholar_Agent.  \n- **Input**: Subtopics/disciplines extracted from the query + insights from publication analysis.  \n- **Output**: Synthesis report with shared challenges, innovation opportunities, complementary methods, and future research pathways.  \n\n**Step 7: Academic Report Generation**  \n- **Action**: Trigger the `generate_academic_report` function.  \n- **Worker Agent Involved**: Research_Scholar_Agent.  \n- **Input**: User\u2019s original research query + combined findings and synthesis.  \n- **Output**: Formal academic report with title, abstract, introduction, literature review, discussion, conclusion, and optional references (with DOIs).  \n\n**Step 8: Deliver Results**  \n- **Action**: Present the academic report to the user in a professional and structured format.  \n- **Meta Agent Responsibility**:  \n  - Ensure the report is comprehensive, accurate, and aligned with the user\u2019s research goals.  \n\n---\n\n#### Additional Guidelines for the Meta Agent  \n1. **Accuracy and Relevance**: Ensure all outputs are accurate, contextually relevant, and tailored to the user\u2019s query.  \n2. **Seamless Workflow Management**: Coordinate tasks between worker agents efficiently, ensuring no step is skipped or mismanaged.  \n3. **Error Handling**: If a worker agent fails or data is unavailable, provide a clear explanation to the user and suggest alternative actions.  \n4. **User Engagement**: Maintain a conversational tone and clarify ambiguities in user queries when necessary.  \n\n--- \n\nThis structured prompt ensures the **Movie_and_scholar_Agent** can effectively manage workflows, leverage worker agents, and deliver high-quality outputs tailored to user needs.\n</code></pre>"},{"location":"agent_config/metaAgent/#agent-updation","title":"Agent Updation","text":"<ol> <li> <p>Add Agents: Click on ADD NEW AGENT, select the agents to add, and then click the UPDATE button to save the changes. </p> </li> <li> <p>Remove Agents: Click on REMOVE MAPPED AGENT, select the agent to remove and then click the UPDATE button to save the changes. </p> </li> <li> <p>Update Workflow: For updating the workflow, Click on Workflow Description and then click on Save button to save the changes. </p> </li> </ol>"},{"location":"agent_config/metaAgent/#agent-deletion","title":"Agent Deletion","text":"<p>Agent Deletion is similar to React Agent Deletion</p>"},{"location":"agent_config/multiAgent/","title":"Multi Agent Configuration","text":"<p>The Multi Agent operates on the Planner-Executor-Critic paradigm. It begins with a Planner Agent that generates a step-by-step plan based on the user query. The Executor Agent then executes each step of the plan. The Critic evaluates the outputs by scoring the results of each step.</p>"},{"location":"agent_config/multiAgent/#multi-agent-onboarding","title":"Multi Agent Onboarding","text":"<p>The following are the steps for onboarding a Multi Agent with an example:</p> <ol> <li> <p>Select Template: Select agent template.</p> <ul> <li><code>Agent Template</code>  MULTI AGENT </li> </ul> </li> <li> <p>Select Tools: from the listed tools - select the tool/s using which we want to create the agent.</p> <ul> <li><code>Tools</code>   get_weather</li> </ul> </li> <li> <p>Agent Name:  Provide a suitable agent name. </p> <ul> <li><code>Agent Name</code>  Weather Agent1</li> </ul> </li> <li> <p>Agent Goal:  Provide goal of the agent - objective of the agent.</p> <ul> <li><code>Agent Goal</code> This agent provides personalized suggestions based on real-time weather data.</li> </ul> </li> <li> <p>Workflow description: Provide detailed instructions to the LLM - Guidelines to the agent. </p> <ul> <li> <p><code>Sample Workflow description</code>:</p> <p>Understand the user intent and perform following steps:</p> <ol> <li>Retrieve Weather Data - Make an API call to fetch real-time weather data.</li> <li>Analyze Weather Conditions - Evaluate the weather data to determine current conditions.</li> <li>Generate Recommendations - Based on the analysis, provide personalized suggestions to the user. </li> </ol> <p>For example:  If the weather is pleasant, suggest outdoor activities.  If the weather is rainy or stormy, advise the user to carry an umbrella or avoid traveling.  If extreme weather conditions are detected, recommend staying indoors and taking necessary precautions.</p> </li> </ul> </li> <li> <p>Model Name: Select the model name from the dropdown - which is used to create system prompt based on provided Agent goal and Workflow description.  </p> </li> </ol> <p>System Prompt:</p> <p>Using the provided agent goal and workflow description, LLM generates system prompts for the planner, executor, and critic agents within a multi-agent template.</p> <p></p>"},{"location":"agent_config/multiAgent/#agent-updation","title":"Agent Updation","text":"<p>Agent Updation is similar to React Agent Updation</p>"},{"location":"agent_config/multiAgent/#agent-deletion","title":"Agent Deletion","text":"<p>Agent Deletion is similar to React Agent Deletion</p>"},{"location":"agent_config/reactAgent/","title":"React Agent Configuration","text":"<p>The ReAct(Reasoning and Acting) agent combines reasoning traces with action execution. It uses a step by step thought process to determine what tool to use, executes it, observe the result, and continues until it can return a final answer.</p>"},{"location":"agent_config/reactAgent/#react-agent-onboarding","title":"React Agent Onboarding","text":"<p>The following are the steps for onboarding the React agent with an example:</p> <ol> <li> <p>Select Template: Select agent template.</p> <ul> <li><code>Agent Template</code>  REACT AGENT </li> </ul> </li> <li> <p>Select Tools: from the listed tools - select the tool/s using which we want to create the agent.</p> <ul> <li><code>Tools</code>   get_weather </li> </ul> </li> <li> <p>Agent Name:  Provide a suitable agent name. </p> <ul> <li><code>Agent Name</code>  Weather Agent</li> </ul> </li> <li> <p>Agent Goal:  Provide goal of the agent - objective of the agent.</p> <ul> <li><code>Agent Goal</code> This agent provides personalized suggestions based on real-time weather data.</li> </ul> </li> <li> <p>Workflow description: Provide detailed instructions to the LLM - Guidelines to the agent. </p> <ul> <li> <p><code>Sample Workflow description</code>:</p> <p>Understand the user intent and perform following steps:</p> <ol> <li>Retrieve Weather Data - Make an API call to fetch real-time weather data.</li> <li>Analyze Weather Conditions - Evaluate the weather data to determine current conditions.</li> <li>Generate Recommendations - Based on the analysis, provide personalized suggestions to the user. </li> </ol> <p>For example:  If the weather is pleasant, suggest outdoor activities.  If the weather is rainy or stormy, advise the user to carry an umbrella or avoid traveling.  If extreme weather conditions are detected, recommend staying indoors and taking necessary precautions.</p> </li> </ul> </li> <li> <p>Model Name: Select the model name from the dropdown - which is used to create system prompt based on provided Agent goal and Workflow description.  </p> </li> </ol> <p>System Prompt: Final guidelines for the agent - created by LLM based on provided Agent goal and Workflow description for the agent.</p> <p>Agent Name Weather Agent</p> <p>Goal to Achieve for the Workflow - The Weather Agent aims to provide personalized suggestions to users based on real-time weather data, enhancing their daily decision-making regarding activities and safety precautions.</p> <p>Guidelines on Tools Provided by the User - Tool Name: get_weather_new - Key Functionalities: This tool retrieves real-time weather data for a specified city using the OpenWeatherMap API. It provides details such as temperature, humidity, pressure, and a brief weather description. - Limitations: The tool requires a valid API key and city name to function. It returns an error message if the HTTP request fails, indicating potential issues with network connectivity or incorrect parameters.</p> <p>Step-by-Step Task Description 1. Retrieve Weather Data: - Use the <code>get_weather_new</code> tool to make an API call with the provided API key and city name. - Ensure the tool successfully fetches the weather data, including temperature, humidity, pressure, and weather description.</p> <ol> <li>Analyze Weather Conditions: </li> <li>Evaluate the retrieved weather data to determine current conditions.</li> <li> <p>Identify key weather attributes such as temperature range, humidity levels, and specific weather phenomena (e.g., rain, storm).</p> </li> <li> <p>Generate Recommendations: </p> </li> <li>Based on the analysis, provide personalized suggestions to the user:<ul> <li>If the weather is pleasant, suggest outdoor activities.</li> <li>If the weather is rainy or stormy, advise the user to carry an umbrella or avoid traveling.</li> <li>If extreme weather conditions are detected, recommend staying indoors and taking necessary precautions.</li> </ul> </li> </ol> <p>Additional Relevant Information - The agent should ensure the recommendations are timely and relevant to the user's location and current weather conditions. - In case of tool failure or unavailability, the agent should inform the user of the inability to provide weather-based suggestions and recommend checking weather updates through other means.</p>"},{"location":"agent_config/reactAgent/#agent-updation","title":"Agent Updation","text":"<ol> <li> <p>Add Tools: Click on ADD NEW TOOL, select the tools to add, and then click the UPDATE button to save the changes. </p> </li> <li> <p>Remove Tools: Click on REMOVE MAPPED TOOL, select the tool to remove and then click the UPDATE button to save the changes. </p> </li> <li> <p>Update Workflow: For updating the workflow, Click on Workflow Description and then click on Save button to save the changes. </p> </li> </ol>"},{"location":"agent_config/reactAgent/#agent-deletion","title":"Agent Deletion","text":"<p>You must provide the creator's email address to delete the agent.</p> <p> </p>"},{"location":"files_upload/files/","title":"Files","text":"<p>This section is used to upload different types of files that may be required by the tools to perform its operation. This may include files such as Database Files (.db),Excel Sheets (.xlsx), Word Documents  (.docx), PDF Files (.pdf) and any other files required by your agent.</p> <p>Supported database files include SQLite (.db, .sqlite) and PostgreSQL dump files (.sql).</p>"},{"location":"files_upload/files/#uploading-files","title":"Uploading Files","text":"<ul> <li>You can upload your files either by clicking the \"Browse\" button or drag and drop the files in the \"Upload\" window. </li> <li>After uploading, all files will be saved in the <code>user_uploads</code> directory.  </li> <li>To access a file through any tool, use the path format: <code>user_uploads/filename.extension</code>.</li> </ul>"},{"location":"files_upload/files/#viewing-downloading-and-deleting-files","title":"Viewing, Downloading and Deleting Files","text":"<p>You can iew the uploaded files and download the uploaded files and delete the uploaded files by clicking on the \"View\", \"Download\" and \"Delete\" button in the \"Files\" section.</p> <p></p>"},{"location":"tools_config/tools/","title":"Tools Configuration","text":""},{"location":"tools_config/tools/#what-are-tools","title":"What Are Tools?","text":"<p>Tools are external functions or actions that an AI agent can call to perform tasks. it can't do with language alone\u2014like searching the web, doing math, or querying a database.</p> <p>Tools give the agent real-world abilities\u2014they act like plugins or helpers that the agent can call when it needs to go beyond generating text.</p> <p>Scenario: The AI agent is asked: \"What\u2019s 1234 multiplied by 9876?\"</p> <ul> <li> <p><code>Without a tool:</code> The agent might try to calculate it just by generating the answer with text prediction. It could get it wrong, especially with large numbers, since LLMs aren\u2019t perfect at arithmetic.</p> </li> <li> <p><code>With a tool:</code> We give the agent access to a calculator tool (a Python function).</p> </li> </ul> <pre><code>def multiply_numbers(x: int, y: int) -&gt; int:\n    return x * y\n</code></pre> <p>Now, when asked \"What\u2019s 1234 multiplied by 9876?\"</p> <p>The agent thinks: This looks like a math problem. I should use the multiply_numbers tool.\" So it calls multiply_numbers(1234, 9876) and fetches the correct result .</p>"},{"location":"tools_config/tools/#tools-format","title":"Tools Format","text":"<p>To maintain consistency and reliability, each tool should follow a standard format While onboarding .</p> <ul> <li><code>Description:</code> A short explanation of what the tool does.</li> <li><code>Code Block:</code> The tool\u2019s logic, properly indented and syntactically correct.</li> <li><code>Created By:</code> Email of the tool creator, used to prevent unauthorized edits.</li> <li><code>Model:</code> Once the  model is selected, a doc string for the tool will be generated.</li> <li><code>Domain Tags:</code> Optional labels (e.g., manufacturing, logistics) indicating the domain the tool applies to.</li> </ul>"},{"location":"tools_config/tools/#onboarding-tool","title":"Onboarding Tool","text":"<p>Let's proceed by using the example of onboarding a Weather Information Retrieval Tool.</p> <p>Step 1: Provide a short description of the tool.  </p> <p>Step 2 Add the python tool code into code snippet. </p> <p>Step 3: Specify the required model and enter your email. </p> <p>Step 4: Select the appropriate domain and click Add Tool . </p>"},{"location":"tools_config/tools/#updating-tool","title":"Updating Tool","text":"<p>If we want to modify a tool that has already been onboarded, we must first ensure that the tool is not currently being referenced by any agent.  </p> <p>If it is, remove the dependency before starting the update process. Once the tool has been updated, you can re-establish the dependency.</p> <p>To update a tool, you must also provide the creator email address</p> <p>Select the Edit option to start editing, and finally click on Update. </p>"},{"location":"tools_config/tools/#deleting-a-tool","title":"Deleting a Tool","text":"<p>If you want to delete an existing tool, make sure to first remove any dependencies from agents that are using it.  </p> <p>Once all dependencies are cleared, you can proceed with deleting the tool.</p> <p>To delete a tool, you must also provide the creator email address</p> <p>Step 1:  Select the Delete option </p> <p>Step 2: Enter the authorized creator\u2019s email ID and click on Delete </p>"}]}